{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import theano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I accomplished the above by running this command at the command prompt:   \n",
    "\n",
    "```    \n",
    "THEANO_FLAGS='mode=FAST_RUN,device=gpu,floatX=float32' jupyter notebook   \n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import theano\n",
    "from theano import function, config, sandbox, shared \n",
    "import theano.tensor as T\n",
    "import numpy as np\n",
    "import scipy\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More `theano` setup in `jupyter` notebook boilerplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu0\n",
      "0.7\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print( theano.config.device )\n",
    "print( theano.config.lib.cnmem)  # cf. http://deeplearning.net/software/theano/library/config.html\n",
    "print( theano.config.print_active_device)# Print active device at when the GPU device is initialized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LogReg-sklearn.ipynb',\n",
       " 'Linear Algebra Shootout: NumPy vs. Theano vs. TensorFlow_files',\n",
       " 'LICENSE',\n",
       " 'theano.pdf',\n",
       " 'deeplearning.pdf',\n",
       " 'sklearn_ML.ipynb',\n",
       " 'LaTeXandpdfs',\n",
       " 'supervised-theano.ipynb',\n",
       " 'sanity_check_theano_uses_gpu.ipynb',\n",
       " '.git',\n",
       " 'README.md',\n",
       " 'Linear Algebra Shootout: NumPy vs. Theano vs. TensorFlow.html',\n",
       " '.ipynb_checkpoints',\n",
       " 'theano_ML.ipynb',\n",
       " 'deep-learning--ud730',\n",
       " 'tf_sanitycheck.ipynb',\n",
       " 'saved_models',\n",
       " 'FedoraNVidiaInstallTips',\n",
       " 'tf',\n",
       " 'kaggle',\n",
       " 'sampleinputdataX.ipynb',\n",
       " 'ML',\n",
       " 'Data',\n",
       " 'simple_logreg.py',\n",
       " 'Speeding up your Neural Network with Theano and the GPU \\xe2\\x80\\x93 WildML_files',\n",
       " 'coursera_Ng',\n",
       " 'MorseTheory.ipynb',\n",
       " 'tutorial_theano.ipynb',\n",
       " 'best_model.pkl',\n",
       " 'gpu_test.py',\n",
       " 'Speeding up your Neural Network with Theano and the GPU \\xe2\\x80\\x93 WildML.html']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, sys\n",
    "os.getcwd()\n",
    "os.listdir( os.getcwd() ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GpuElemwise{exp,no_inplace}(<CudaNdarrayType(float32, vector)>), HostFromGpu(GpuElemwise{exp,no_inplace}.0)]\n",
      "Looping 1000 times took 0.211632 seconds\n",
      "Result is [ 1.23178029  1.61879349  1.52278066 ...,  2.20771813  2.29967761\n",
      "  1.62323296]\n",
      "Used the gpu\n"
     ]
    }
   ],
   "source": [
    "%run gpu_test.py THEANO_FLAGS='mode=FAST_RUN,device=gpu,floatX=float32,lib.cnmem=0.85' # note lib.cnmem option for CnMem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sample data boilerplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the diabetes dataset\n",
    "diabetes = sklearn.datasets.load_diabetes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "diabetes_X = diabetes.data\n",
    "diabetes_Y = diabetes.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#diabetes_X1 = diabetes_X[:,np.newaxis,2]\n",
    "diabetes_X1 = diabetes_X[:,np.newaxis, 2].astype(theano.config.floatX)\n",
    "#diabetes_Y  = diabetes_Y.reshape( diabetes_Y.shape[0], 1)\n",
    "diabetes_Y = diabetes_Y.astype(theano.config.floatX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "cf. [Linear Regression In Theano](https://roshansanthosh.wordpress.com/2015/02/22/linear-regression-in-theano/)\n",
    "\n",
    "[`1_linear_regression.py` from `github` Newmu/Theano-Tutorials](https://github.com/Newmu/Theano-Tutorials/blob/master/1_linear_regression.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train on $m$ number of input data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_lin = diabetes_X1.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input, output variables $x$, $y$ for Theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x1 = T.vector('x1')  # X1, input data, with only 1 feature, i.e. X \\in \\mathbb{R}^N, d=1 \n",
    "#ylin = T.vector('ylin') # target variable for linear regression, so that Y \\in \\mathbb{R}\n",
    "\n",
    "x1 = T.scalar('x1')  # X1, input data, with only 1 feature, i.e. X \\in \\mathbb{R}^N, d=1 \n",
    "ylin = T.scalar('ylin') # target variable for linear regression, so that Y \\in \\mathbb{R}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters (for a linear slope)  \n",
    "\n",
    "$$    \n",
    "(\\theta^0, \\theta^1) \\in \\mathbb{R}^2   \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "thet0_init_val = np.random.randn()\n",
    "thet1_init_val = np.random.randn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "thet0 = theano.shared( value=thet0_init_val, name='thet0', borrow=True)  # \\theta^0\n",
    "thet1 = theano.shared( thet1_init_val, name='thet1', borrow=True)   # \\theta^1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hypothesis function $h_{\\theta}$\n",
    "\n",
    "$$   \n",
    "h_{\\theta}(x) = \\theta_1 x + \\theta_0\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#h_thet = T.dot( thet1, x1) + thet0\n",
    "# whereas, Newmu uses\n",
    "h_thet = thet1 * x1 + thet0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost function $J(\\theta)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roshansanthosh uses \n",
    "#Jthet = T.sum( T.pow(h_thet-ylin,2))/(2*m_lin)\n",
    "\n",
    "# whereas, Newmu uses\n",
    "# Jthet = T.mean( T.sqr( thet_1*x1 + thet_0 - ylin ))\n",
    "\n",
    "Jthet = T.mean( T.pow( h_thet-ylin,2))/2\n",
    "#Jthet = sandbox.cuda.basic_ops.gpu_from_host( T.mean( \n",
    "#        sandbox.cuda.basic_ops.gpu_from_host( T.pow( h_thet-ylin,2))))/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{grad}_{\\theta}J(\\theta) = ( \\text{grad}_{\\theta^0} J , \\text{grad}_{\\theta^1} J )   \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_thet0 = T.grad(Jthet, thet0)\n",
    "grad_thet1 = T.grad(Jthet, thet1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# so-called \"learning rate\"\n",
    "gamma = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that \"**updates** (iterable over pairs (shared_variable, new_expression) List, tuple or dict.) â€“ expressions for new SharedVariable values\" cf. [Theano doc](http://deeplearning.net/software/theano/library/compile/function.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lin = theano.function(inputs = [x1,ylin], outputs=Jthet, \n",
    "                        updates=[[thet1,thet1-gamma*grad_thet1],[thet0,thet0-gamma*grad_thet0]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_lin = theano.function([x1],h_thet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X1_lin_in = shared( diabetes_X1 ,'float32')\n",
    "#Y_lin_out = shared( diabetes_Y, 'float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_steps = 1000 # 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sh_diabetes_X1 = shared( diabetes_X1 , borrow=True)\n",
    "sh_diabetes_Y  = shared( diabetes_Y, borrow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "('Bad input argument to theano function with name \"<ipython-input-34-92f3da11396a>:2\"  at index 0(0-based)', 'Expected an array-like object, but found a Variable: maybe you are trying to call a function on a (possibly shared) variable instead of a numeric array?')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-b6192b29b89d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#    for x,y in zip( sh_diabetes_X1, sh_diabetes_Y) :\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m#        Jthet_val = train_lin( x,y)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mJthet_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_lin\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0msh_diabetes_X1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msh_diabetes_Y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/topolo/Public/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    784\u001b[0m                         s.storage[0] = s.type.filter(\n\u001b[0;32m    785\u001b[0m                             \u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 786\u001b[1;33m                             allow_downcast=s.allow_downcast)\n\u001b[0m\u001b[0;32m    787\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/topolo/Public/anaconda2/lib/python2.7/site-packages/theano/tensor/type.pyc\u001b[0m in \u001b[0;36mfilter\u001b[1;34m(self, data, strict, allow_downcast)\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m             raise TypeError(\n\u001b[1;32m---> 86\u001b[1;33m                 \u001b[1;34m'Expected an array-like object, but found a Variable: '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m                 \u001b[1;34m'maybe you are trying to call a function on a (possibly '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m                 'shared) variable instead of a numeric array?')\n",
      "\u001b[1;31mTypeError\u001b[0m: ('Bad input argument to theano function with name \"<ipython-input-34-92f3da11396a>:2\"  at index 0(0-based)', 'Expected an array-like object, but found a Variable: maybe you are trying to call a function on a (possibly shared) variable instead of a numeric array?')"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "for i in range(training_steps):\n",
    "    for x,y in zip( diabetes_X1, diabetes_Y):\n",
    "        Jthet_val = train_lin( x, y )\n",
    "        \"\"\"\n",
    "\n",
    "for i in range(training_steps):\n",
    "#    for x,y in zip( sh_diabetes_X1, sh_diabetes_Y) :\n",
    "#        Jthet_val = train_lin( x,y)\n",
    "    Jthet_val = train_lin( sh_diabetes_X1, sh_diabetes_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Jthet_val' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-49f3322b82c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mJthet_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Jthet_val' is not defined"
     ]
    }
   ],
   "source": [
    "print(Jthet_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151.746080721\n",
      "942.701275851\n"
     ]
    }
   ],
   "source": [
    "print( thet0.get_value() ); print( thet1.get_value() )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lin_out = np.array( [ test_lin( x ) for x in diabetes_X1 ] ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f4037fd3790>]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEACAYAAABbMHZzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQf4/6baZTu0/qIoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f403e5b60d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(diabetes_X1,diabetes_Y,'ro')\n",
    "plt.plot(diabetes_X1,test_lin_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Elemwise{Composite{(((i0 * i1) + i2) - i3)}}(thet1, x1, thet0, ylin), Elemwise{Composite{(i0 - (i1 * i2))}}[(0, 0)](thet0, TensorConstant{0.00999999977648}, Elemwise{Composite{(((i0 * i1) + i2) - i3)}}.0), Elemwise{Composite{(i0 - (i1 * i2 * i3))}}[(0, 0)](thet1, TensorConstant{0.00999999977648}, Elemwise{Composite{(((i0 * i1) + i2) - i3)}}.0, x1), Elemwise{Composite{(i0 * sqr(i1))}}[(0, 1)](TensorConstant{0.5}, Elemwise{Composite{(((i0 * i1) + i2) - i3)}}.0)]\n"
     ]
    }
   ],
   "source": [
    "if any([x.op.__class__.__name__ in ['GpuGemm','GpuGemv'] for x in train_lin.maker.fgraph.toposort()]):\n",
    "    print(\"Used the gpu\")\n",
    "else:\n",
    "    print(train_lin.maker.fgraph.toposort())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used the cpu\n"
     ]
    }
   ],
   "source": [
    "if np.any([isinstance(x.op,T.Elemwise) for x in train_lin.maker.fgraph.toposort()]):\n",
    "    print(\"Used the cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Algebra and `theano`\n",
    "\n",
    "cf. [Week 1, Linear Algebra Review, Coursera, Machine Learning with Ng](https://www.coursera.org/learn/machine-learning/lecture/38jIT/matrices-and-vectors)\n",
    "\n",
    "I'll take this opportunity to provide a dictionary between the syntax of linear algebra math and `numpy`.   \n",
    "\n",
    "Essentially, what I did was take Coursera's [Week 1, Linear Algebra Review](https://www.coursera.org/learn/machine-learning/lecture/dpF1j/matrix-matrix-multiplication) and then translated the math into **`theano`**, and in particular, running theano on the **GPU**.\n",
    "\n",
    "Other reference that I used was \n",
    "\n",
    "https://simplyml.com/linear-algebra-shootout-numpy-vs-theano-vs-tensorflow-2/\n",
    "\n",
    "[Linear Algebra Shootout: NumPy vs. Theano vs. TensorFlow by Charanpal Dhanjal - 14/07/16 ](https://simplyml.com/linear-algebra-shootout-numpy-vs-theano-vs-tensorflow-2/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrix addition\n",
    "\n",
    "cf. [Coursera, Intro. to Machine Learning, Linear Algebra Review, Addition and Scalar Multiplication](https://www.coursera.org/learn/machine-learning/lecture/R4hiJ/addition-and-scalar-multiplication)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A = T.matrix('A')\n",
    "B = T.matrix('B')\n",
    "#matadd = function([A,B], A+B)\n",
    "#matadd = function([A,B],sandbox.cuda.basic_ops.gpu_from_host(A+B) )\n",
    "# Note: we are just defining the expressions, nothing is evaluated here!  \n",
    "C = sandbox.cuda.basic_ops.gpu_from_host(A+B)\n",
    "matadd = function([A,B], C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#A = T.dmatrix('A')\n",
    "#B = T.dmatrix('B')\n",
    "\n",
    "A = T.matrix('A')\n",
    "B = T.matrix('B')\n",
    "\n",
    "C_out = A + B\n",
    "matadd_CPU = function([A,B], C_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A_eg = shared( np.array([[8,6,9],[10,1,10]]), 'float32')\n",
    "B_eg = shared( np.array([[3,10,2],[6,1,-1]]), 'float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_eg_CPU = np.array([[8,6,9],[10,1,10]])\n",
    "B_eg_CPU = np.array([[3,10,2],[6,1,-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8  6  9]\n",
      " [10  1 10]]\n",
      "<type 'numpy.ndarray'>\n",
      "(2, 3)\n",
      "(2, 3)\n"
     ]
    }
   ],
   "source": [
    "print(A_eg_CPU)\n",
    "print( type( A_eg_CPU ))\n",
    "print( A_eg_CPU.shape)\n",
    "print( B_eg_CPU.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GpuFromHost(B), GpuFromHost(A), GpuElemwise{Add}[(0, 0)](GpuFromHost.0, GpuFromHost.0)]\n"
     ]
    }
   ],
   "source": [
    "print( matadd.maker.fgraph.toposort() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GpuFromHost(B), GpuFromHost(A), GpuElemwise{Add}[(0, 0)](GpuFromHost.0, GpuFromHost.0), HostFromGpu(GpuElemwise{Add}[(0, 0)].0)]\n"
     ]
    }
   ],
   "source": [
    "print( matadd_CPU.maker.fgraph.toposort() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "('Bad input argument to theano function with name \"<ipython-input-69-40293d053d65>:7\"  at index 0(0-based)', 'Expected an array-like object, but found a Variable: maybe you are trying to call a function on a (possibly shared) variable instead of a numeric array?')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-71-dd6866f5ad02>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmatadd\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mA_eg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mB_eg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/topolo/Public/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    784\u001b[0m                         s.storage[0] = s.type.filter(\n\u001b[0;32m    785\u001b[0m                             \u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 786\u001b[1;33m                             allow_downcast=s.allow_downcast)\n\u001b[0m\u001b[0;32m    787\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/topolo/Public/anaconda2/lib/python2.7/site-packages/theano/tensor/type.pyc\u001b[0m in \u001b[0;36mfilter\u001b[1;34m(self, data, strict, allow_downcast)\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m             raise TypeError(\n\u001b[1;32m---> 86\u001b[1;33m                 \u001b[1;34m'Expected an array-like object, but found a Variable: '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m                 \u001b[1;34m'maybe you are trying to call a function on a (possibly '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m                 'shared) variable instead of a numeric array?')\n",
      "\u001b[1;31mTypeError\u001b[0m: ('Bad input argument to theano function with name \"<ipython-input-69-40293d053d65>:7\"  at index 0(0-based)', 'Expected an array-like object, but found a Variable: maybe you are trying to call a function on a (possibly shared) variable instead of a numeric array?')"
     ]
    }
   ],
   "source": [
    "matadd( A_eg, B_eg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way to do it, to \"force\" on the GPU, is like this (cf. [Speeding up your Neural Network with Theano and the GPU - Wild ML](http://www.wildml.com/2015/09/speeding-up-your-neural-network-with-theano-and-the-gpu/)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.01645633,  0.49394088, -0.22904526],\n",
       "       [-0.44323914, -0.27948502,  0.335645  ]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randn( *A_eg_CPU.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_out = theano.shared( np.random.randn( *A_eg_CPU.shape).astype('float32') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<CudaNdarrayType(float32, matrix)>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_out.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A_in = shared( A_eg_CPU, \"float32\")\n",
    "#A_in = shared( A_eg_CPU, \"float32\")\n",
    "\n",
    "A_in = shared( A_eg_CPU.astype(\"float32\"), \"float32\")\n",
    "B_in = shared( B_eg_CPU.astype(\"float32\"), \"float32\")\n",
    "#C_out_GPU = A_in + B_in\n",
    "C_out_GPU = sandbox.cuda.basic_ops.gpu_from_host(A_in+B_in)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "matadd_GPU = theano.function( [], C_out_GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "C_out_GPU_result = matadd_GPU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CudaNdarray([[ 11.  16.  11.]\n",
       " [ 16.   2.   9.]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_out_GPU_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how **DIFFERENT** this setup or syntax is: we have to set up tensor or matrix *shared variables* `A_n`, `B_in`, which are then used to define the theano function, `theano.function`.  \"By using shared variables we ensure that they are present in the GPU memory\".  cf. [Linear Algebra Shootout: NumPy vs. Theano vs. TensorFlow](https://simplyml.com/linear-algebra-shootout-numpy-vs-theano-vs-tensorflow-2/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GpuElemwise{add,no_inplace}(float32, float32)]\n"
     ]
    }
   ],
   "source": [
    "print( matadd_GPU.maker.fgraph.toposort() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CudaNdarrayVariable' object has no attribute 'op'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-128-eedabe693a3f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#if np.any([isinstance(C_out_GPU.op, tensor.Elemwise ) and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m if np.any([isinstance( C_out_GPU.op, T.Elemwise ) and \n\u001b[1;32m----> 3\u001b[1;33m            ('Gpu' not in type( C_out_GPU.op).__name__) for x in matadd_GPU.maker.fgraph.toposort()]) :\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Used the cpu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'CudaNdarrayVariable' object has no attribute 'op'"
     ]
    }
   ],
   "source": [
    "#if np.any([isinstance(C_out_GPU.op, tensor.Elemwise ) and \n",
    "if np.any([isinstance( C_out_GPU.op, T.Elemwise ) and \n",
    "           ('Gpu' not in type( C_out_GPU.op).__name__) for x in matadd_GPU.maker.fgraph.toposort()]) :\n",
    "    print('Used the cpu')\n",
    "else:\n",
    "    print('Used the gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 11.,  16.,  11.],\n",
       "       [ 16.,   2.,   9.]], dtype=float32)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matadd_CPU( A_eg_CPU.astype(\"float32\"), B_eg_CPU.astype(\"float32\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "theano.tensor.sharedvar.TensorSharedVariable"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(A_eg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2000,)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print( type( numpy.asarray(rng.rand(2000)) ) )\n",
    "numpy.asarray(rng.rand(2000)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bottom Line:** there are **2** ways of doing linear algebra *on the GPU*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. symbolic computation with the usual arguments    \n",
    "\n",
    "$$\n",
    "A + B = C \\in \\text{Mat}_{\\mathbb{R}}(M,N)   \n",
    "$$   \n",
    "\n",
    "$ \\forall \\, A, B \\in \\text{Mat}_{\\mathbb{R}}(M,N)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A = T.matrix('A')\n",
    "B = T.matrix('B')\n",
    "\n",
    "C = sandbox.cuda.basic_ops.gpu_from_host( A + B ) # vs. \n",
    "# C = A + B  # this will result in an output array on the host, as opposed to CudaNdarray on device\n",
    "matadd = function([A,B], C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GpuFromHost(B), GpuFromHost(A), GpuElemwise{Add}[(0, 0)](GpuFromHost.0, GpuFromHost.0)]\n"
     ]
    }
   ],
   "source": [
    "print( matadd.maker.fgraph.toposort() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CudaNdarray([[ 11.  16.  11.]\n",
       " [ 16.   2.   9.]])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matadd( A_eg_CPU.astype(\"float32\"), B_eg_CPU.astype(\"float32\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. with *shared variables*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A_in = shared( A_eg_CPU.astype(\"float32\"), \"float32\")  # initialize with the input values, A_eg_CPU, anyway\n",
    "B_in = shared( B_eg_CPU.astype(\"float32\"), \"float32\")  # initialize with the input values B_eg_CPU, anyway\n",
    "\n",
    "# C_out = A_in + B_in # this version will output to the host as a numpy.ndarray\n",
    "# indeed, reading the graph,\n",
    "\"\"\"\n",
    "[GpuElemwise{add,no_inplace}(float32, float32), HostFromGpu(GpuElemwise{add,no_inplace}.0)]\n",
    "\"\"\"\n",
    "# this version immediately below, in 1 line, will result in a CudaNdarray on device\n",
    "C_out = sandbox.cuda.basic_ops.gpu_from_host(A_in+B_in)\n",
    "\n",
    "matadd_GPU = theano.function( [], C_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GpuElemwise{add,no_inplace}(float32, float32)]\n"
     ]
    }
   ],
   "source": [
    "print( matadd_GPU.maker.fgraph.toposort() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "C_out_result = matadd_GPU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CudaNdarray([[ 11.  16.  11.]\n",
       " [ 16.   2.   9.]])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_out_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scalar Multiplication (on the GPU)\n",
    "\n",
    "cf. [Scalar Multiplication of Linear Algebra Review, coursera, Machine Learning Intro by Ng](https://www.coursera.org/learn/machine-learning/lecture/R4hiJ/addition-and-scalar-multiplication)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_2 = np.array( [[4,5],[1,7] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = T.scalar('a')\n",
    "\n",
    "F = sandbox.cuda.basic_ops.gpu_from_host( a*A )\n",
    "scalarmul = theano.function([a,A],F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GpuFromHost(A), GpuFromHost(a), GpuDimShuffle{x,x}(GpuFromHost.0), GpuElemwise{Mul}[(0, 1)](GpuDimShuffle{x,x}.0, GpuFromHost.0)]\n"
     ]
    }
   ],
   "source": [
    "print( scalarmul.maker.fgraph.toposort() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CudaNdarray([[  8.  10.]\n",
       " [  2.  14.]])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalarmul( np.float32( 2.), A_2.astype(\"float32\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Composition; Confirming that you can do composition of scalar multiplication on a matrix (or ring) addition\n",
    "\n",
    "Being able to do composition is *very important* in math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CudaNdarray([[ 22.  32.  22.]\n",
       " [ 32.   4.  18.]])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalarmul( np.float32(2.), matadd( A_eg_CPU.astype(\"float32\"), B_eg_CPU.astype(\"float32\") ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = T.vector('u')\n",
    "v = T.vector('v')\n",
    "\n",
    "w = sandbox.cuda.basic_ops.gpu_from_host( u + v)\n",
    "vecadd = theano.function( [u,v],w)\n",
    "\n",
    "t = sandbox.cuda.basic_ops.gpu_from_host( a * u)\n",
    "scalarmul_vec = theano.function([a,u], t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GpuFromHost(v), GpuFromHost(u), GpuElemwise{Add}[(0, 0)](GpuFromHost.0, GpuFromHost.0)]\n",
      "[GpuFromHost(u), GpuFromHost(a), GpuDimShuffle{x}(GpuFromHost.0), GpuElemwise{Mul}[(0, 1)](GpuDimShuffle{x}.0, GpuFromHost.0)]\n"
     ]
    }
   ],
   "source": [
    "print(vecadd.maker.fgraph.toposort())  \n",
    "print(scalarmul_vec.maker.fgraph.toposort())  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "u_eg = np.array( [4,6,7], dtype=\"float32\")\n",
    "v_eg = np.array( [2,1,0], dtype=\"float32\")\n",
    "\n",
    "print( u_eg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CudaNdarray([ 2.   3.   3.5])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalarmul_vec( np.float32(0.5), u_eg )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CudaNdarray([-4.   0.   3.5])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vecadd( scalarmul_vec( np.float32(0.5), u_eg ) , scalarmul_vec( np.float32(-3.), v_eg )  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was the computer equivalent to mathematical expression:  \n",
    "\n",
    "$$   \n",
    "\\left[ \\begin{matrix} 4 \\\\ 6 \\\\ 7 \\end{matrix} \\right] /2 - 3 * \\left[ \\begin{matrix} 2 \\\\ 1 \\\\ 0 \\end{matrix} \\right]\n",
    "$$   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sAxy or A-V multiplication or so-called \"Gemv\", or Matrix Multiplication on a vector, or linear transformation on a R-module, or vector space   \n",
    "\n",
    "i.e.   \n",
    "\n",
    "$$\n",
    "Av = B   \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GpuFromHost(v), GpuFromHost(A), Shape_i{0}(A), GpuAllocEmpty(Shape_i{0}.0), GpuGemv{inplace}(GpuAllocEmpty.0, TensorConstant{1.0}, GpuFromHost.0, GpuFromHost.0, TensorConstant{0.0})]\n"
     ]
    }
   ],
   "source": [
    "B_out = sandbox.cuda.basic_ops.gpu_from_host( T.dot(A,v))\n",
    "AVmul = theano.function([A,v], B_out)\n",
    "print(AVmul.maker.fgraph.toposort())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CudaNdarray([  7.  18.  13.])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AVmul( np.array([[1,0,3],[2,1,5],[3,1,2]]).astype(\"float32\"), np.array([1,6,2]).astype(\"float32\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CudaNdarray([ 1.  6.  2.])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AVmul( np.array([[1,0,0],[0,1,0],[0,0,1]]).astype(\"float32\"), np.array([1,6,2]).astype(\"float32\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AB or Gemm or Matrix Multiplication, i.e. Ring multiplication   \n",
    "\n",
    "i.e.   \n",
    "$$  \n",
    "A*B = C  \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GpuFromHost(B), GpuFromHost(A), GpuDot22(GpuFromHost.0, GpuFromHost.0)]\n"
     ]
    }
   ],
   "source": [
    "C_f = sandbox.cuda.basic_ops.gpu_from_host( T.dot(A,B)) \n",
    "matmul = theano.function([A,B], C_f)\n",
    "print( matmul.maker.fgraph.toposort())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CudaNdarray([[  7.   9.]\n",
       " [ 10.  12.]\n",
       " [ 10.  15.]])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matmul( np.array( [[1,3],[2,4],[0,5]]  ).astype(\"float32\"), np.array([[1,0],[2,3]]).astype(\"float32\")  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverse and Transpose   \n",
    "\n",
    "cf. [Inverse and Transpose](https://www.coursera.org/learn/machine-learning/lecture/FuSWY/inverse-and-transpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GpuFromHost(A), GpuElemwise{Inv}[(0, 0)](GpuFromHost.0)]\n"
     ]
    }
   ],
   "source": [
    "Ainverse = sandbox.cuda.basic_ops.gpu_from_host( T.inv(A))\n",
    "Ainv = theano.function([A], Ainverse)\n",
    "print(Ainv.maker.fgraph.toposort())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GpuFromHost(A), GpuDimShuffle{1,0}(GpuFromHost.0)]\n"
     ]
    }
   ],
   "source": [
    "Atranspose = sandbox.cuda.basic_ops.gpu_from_host( A.T)\n",
    "AT = theano.function([A],Atranspose)\n",
    "print(AT.maker.fgraph.toposort())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summation, sum, mean, scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression (again), via Coursera's Machine Learning Intro by Ng, Programming Exercise 1 for Week 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boilerplate, load sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "linregdata = pd.read_csv('./coursera_Ng/machine-learning-ex1/ex1/ex1data1.txt', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((97, 1), <type 'numpy.ndarray'>)\n",
      "((97, 1), <type 'numpy.ndarray'>)\n",
      "97\n"
     ]
    }
   ],
   "source": [
    "X_linreg_training = linregdata.as_matrix([0])  # pandas.DataFrame.as_matrix convert frame to its numpy-array representation\n",
    "y_linreg_training = linregdata.as_matrix([1])\n",
    "m_linreg_training = len(y_linreg_training)  # number of training examples  \n",
    "print( X_linreg_training.shape, type(X_linreg_training)) \n",
    "print( y_linreg_training.shape, type(y_linreg_training)) \n",
    "print m_linreg_training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try representing $\\theta$, parameters or \"weights\", of size $|\\theta|$ which should be equal to the number of features $n$ (or $d$).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# theta_linreg = T.vector('theta_linreg')\n",
    "d = X_linreg_training.shape[1] # d = features\n",
    "\n",
    "# Declare Theano symbolic variables\n",
    "X = T.matrix('x')\n",
    "y = T.vector('y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess training data (due to numpy's treatment of arrays) (note, this is not needed, if you use pandas to choose which column(s) you want to make into a numpy array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_linreg_training = X_linreg_training.reshape( m_linreg_training,1)\n",
    "#y_linreg_training = y_linreg_training.reshape( m_linreg_training,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead, the training data X and test data values y are going to be represented by Theano symbolic variable above\n",
    "#X_linreg = theano.shared(X_linreg_training.astype(\"float32\"),\"float32\")\n",
    "#y_linreg = theano.shared(y_linreg_training.astype(\"float32\"),\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.]\n"
     ]
    }
   ],
   "source": [
    "#theta_0 = np.zeros( ( d+1,1)); print(theta_0)\n",
    "theta_0 = np.zeros(  d+1); print(theta_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = theano.shared( theta_0.astype(\"float32\"), \"theta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha = np.float32(0.01) # learning rate gamma or alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Construct Theano \"expression graph\"\n",
    "\n",
    "predicted_vals = sandbox.cuda.basic_ops.gpu_from_host( T.dot(X,theta) )  # h_{\\theta}\n",
    "m = np.float32( y_linreg_training.shape[0] ) \n",
    "J_theta = sandbox.cuda.basic_ops.gpu_from_host( \n",
    "    T.dot( (T.dot(X,theta) - y).T, T.dot(X,theta) - y)  * np.float32( 0.5 ) * np.float32( 1./ m )   \n",
    "    ) # cost function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_theta = sandbox.cuda.basic_ops.gpu_from_host( \n",
    "        theta - alpha * T.grad( J_theta, theta) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradientDescent = theano.function( \n",
    "                            inputs=[X,y],\n",
    "                            outputs=[predicted_vals,J_theta],  \n",
    "                            updates=[(theta, update_theta)], \n",
    "                            name = \"gradientDescent\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GpuFromHost(x), Shape_i{0}(x), GpuFromHost(y), GpuAllocEmpty(TensorConstant{1}), GpuDimShuffle{1,0}(GpuFromHost.0), GpuAllocEmpty(Shape_i{0}.0), GpuGemv{inplace}(GpuAllocEmpty.0, TensorConstant{1.0}, GpuFromHost.0, theta, TensorConstant{0.0}), GpuElemwise{Sub}[(0, 1)](GpuGemv{inplace}.0, GpuFromHost.0), GpuDimShuffle{0}(GpuElemwise{Sub}[(0, 1)].0), GpuDimShuffle{x,0}(GpuElemwise{Sub}[(0, 1)].0), GpuGemv{inplace}(GpuAllocEmpty.0, TensorConstant{1.0}, GpuDimShuffle{x,0}.0, GpuDimShuffle{0}.0, TensorConstant{0.0}), GpuElemwise{Mul}[(0, 1)](CudaNdarrayConstant{[ 0.00515464]}, GpuElemwise{Sub}[(0, 1)].0), GpuDimShuffle{}(GpuGemv{inplace}.0), GpuGemv{inplace}(theta, TensorConstant{-0.019999999553}, GpuDimShuffle{1,0}.0, GpuElemwise{Mul}[(0, 1)].0, TensorConstant{1.0}), GpuElemwise{Mul}[(0, 1)](CudaNdarrayConstant{0.00515463901684}, GpuDimShuffle{}.0)]\n"
     ]
    }
   ],
   "source": [
    "print( gradientDescent.maker.fgraph.toposort() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_iters = 1500\n",
    "J_History = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess X to *include intercepts*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_X_linreg = np.hstack( ( np.ones((m_linreg_training,1)), X_linreg_training ) ).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_linreg_training_processed = y_linreg_training.reshape( m_linreg_training,).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "J_History = [0 for iter in range(num_iters)]\n",
    "for iter in range(num_iters):\n",
    "    predicted_vals_out, J_out = \\\n",
    "        gradientDescent(input_X_linreg.astype(\"float32\"), y_linreg_training_processed.astype(\"float32\") ) \n",
    "    J_History[iter] = J_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Deg = (np.random.randn(40,10).astype(\"float32\"), np.random.randint(size=40,low=0,high=2).astype(\"float32\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 10)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Deg[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Deg[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.63029242,  1.1663624 ], dtype=float32)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta.get_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__add__',\n",
       " '__array__',\n",
       " '__class__',\n",
       " '__copy__',\n",
       " '__deepcopy__',\n",
       " '__delattr__',\n",
       " '__delitem__',\n",
       " '__doc__',\n",
       " '__format__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__hash__',\n",
       " '__iadd__',\n",
       " '__idiv__',\n",
       " '__init__',\n",
       " '__len__',\n",
       " '__new__',\n",
       " '__radd__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '_dev_data',\n",
       " '_set_shape_i',\n",
       " '_set_stride',\n",
       " '_strides',\n",
       " 'base',\n",
       " 'copy',\n",
       " 'dtype',\n",
       " 'exp',\n",
       " 'gpudata',\n",
       " 'is_c_contiguous',\n",
       " 'mem_size',\n",
       " 'ndim',\n",
       " 'reduce_sum',\n",
       " 'reshape',\n",
       " 'shape',\n",
       " 'size',\n",
       " 'strides',\n",
       " 'take',\n",
       " 'view',\n",
       " 'zeros']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir( J_History[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47407335424"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J_History[-5].gpudata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ffa1c17a7d0>]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAEDCAYAAAASpvJbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nz+mUhVavhD0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ffa1c5d6410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot( [ele.gpudata for ele in J_History])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Denny Britz's way:  \n",
    "\n",
    "http://www.wildml.com/2015/09/speeding-up-your-neural-network-with-theano-and-the-gpu/\n",
    "\n",
    "[Speeding up your Neural Network with Theano and the GPU](http://www.wildml.com/2015/09/speeding-up-your-neural-network-with-theano-and-the-gpu/)\n",
    "\n",
    "and his jupyter notebook\n",
    "\n",
    "https://github.com/dennybritz/nn-theano/blob/master/nn-theano-gpu.ipynb\n",
    "\n",
    "[ `nn-theano/nn-theano-gpu.ipynb`](https://github.com/dennybritz/nn-theano/blob/master/nn-theano-gpu.ipynb)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97, 2)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_X_linreg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GPU NOTE: Conversion to float32 to store them on the GPU!\n",
    "X = theano.shared( input_X_linreg.astype('float32'), name='X' )\n",
    "y = theano.shared( y_linreg_training.astype('float32'), name='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU NOTE: Conversion to float32 to store them on the GPU!  \n",
    "theta = theano.shared( np.vstack(theta_0).astype(\"float32\"), name='theta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct Theano \"expression graph\"\n",
    "\n",
    "predicted_vals = sandbox.cuda.basic_ops.gpu_from_host( \n",
    "    T.dot(X,theta) )  # h_{\\theta}\n",
    "m = np.float32( y_linreg_training.shape[0] )\n",
    "# cost function J_theta, J_{\\theta}\n",
    "J_theta = sandbox.cuda.basic_ops.gpu_from_host( \n",
    "    (\n",
    "        T.dot( (T.dot(X,theta) - y).T, T.dot(X,theta) - y) * np.float32(0.5) * np.float32( 1./m)  \n",
    "    ).reshape([]) )   # cost function  # reshape is to force \"broadcast\" into 0-dim. scalar for cost function\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_theta = sandbox.cuda.basic_ops.gpu_from_host( \n",
    "        theta - alpha * T.grad( J_theta, theta) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Note that we removed the input values because we will always use the same shared variable\n",
    "# GPU Note: Removed the input values to avoid copying data to the GPU.\n",
    "gradientDescent = theano.function( \n",
    "                            inputs=[],\n",
    "#                            outputs=[predicted_vals,J_theta],  \n",
    "                            updates=[(theta, update_theta)], \n",
    "                            name = \"gradientDescent\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Shape_i{1}(theta), GpuDimShuffle{1,0}(X), GpuGemm{no_inplace}(y, TensorConstant{1.0}, X, theta, TensorConstant{-1.0}), MakeVector{dtype='int64'}(Shape_i{1}.0, Shape_i{1}.0), GpuReshape{2}(CudaNdarrayConstant{1.0}, MakeVector{dtype='int64'}.0), GpuElemwise{mul,no_inplace}(CudaNdarrayConstant{[[ 0.00515464]]}, GpuReshape{2}.0), GpuDot22(GpuGemm{no_inplace}.0, GpuElemwise{mul,no_inplace}.0), GpuDimShuffle{1,0}(GpuElemwise{mul,no_inplace}.0), GpuDot22(GpuGemm{no_inplace}.0, GpuDimShuffle{1,0}.0), GpuGemm{inplace}(theta, TensorConstant{-0.00999999977648}, GpuDimShuffle{1,0}.0, GpuDot22.0, TensorConstant{1.0}), GpuGemm{inplace}(GpuGemm{inplace}.0, TensorConstant{-0.00999999977648}, GpuDimShuffle{1,0}.0, GpuDot22.0, TensorConstant{1.0})]\n"
     ]
    }
   ],
   "source": [
    "print( gradientDescent.maker.fgraph.toposort() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#J_History = [0 for iter in range(num_iters)]\n",
    "for iter in range(num_iters):\n",
    "    gradientDescent( ) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1)\n",
      "(97, 1)\n"
     ]
    }
   ],
   "source": [
    "print( np.vstack( theta_0).shape )\n",
    "print( y_linreg_training.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.63076854],\n",
       "       [ 1.16641033]], dtype=float32)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta.get_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Profiling\n",
    "print( theano.config.profile )  # Do the vm/cvm linkers profile the execution time of Theano functions?\n",
    "print( theano.config.profile_memory ) # Do the vm/cvm linkers profile the memory usage of Theano functions? It only works when profile=True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GpuGemm{inplace} [id A] ''   10\n",
      " |GpuGemm{inplace} [id B] ''   9\n",
      " | |theta [id C]\n",
      " | |TensorConstant{-0.00999999977648} [id D]\n",
      " | |GpuDimShuffle{1,0} [id E] ''   1\n",
      " | | |X [id F]\n",
      " | |GpuDot22 [id G] ''   8\n",
      " | | |GpuGemm{no_inplace} [id H] ''   2\n",
      " | | | |y [id I]\n",
      " | | | |TensorConstant{1.0} [id J]\n",
      " | | | |X [id F]\n",
      " | | | |theta [id C]\n",
      " | | | |TensorConstant{-1.0} [id K]\n",
      " | | |GpuDimShuffle{1,0} [id L] ''   7\n",
      " | |   |GpuElemwise{mul,no_inplace} [id M] ''   5\n",
      " | |     |CudaNdarrayConstant{[[ 0.00515464]]} [id N]\n",
      " | |     |GpuReshape{2} [id O] ''   4\n",
      " | |       |CudaNdarrayConstant{1.0} [id P]\n",
      " | |       |MakeVector{dtype='int64'} [id Q] ''   3\n",
      " | |         |Shape_i{1} [id R] ''   0\n",
      " | |         | |theta [id C]\n",
      " | |         |Shape_i{1} [id R] ''   0\n",
      " | |TensorConstant{1.0} [id J]\n",
      " |TensorConstant{-0.00999999977648} [id D]\n",
      " |GpuDimShuffle{1,0} [id E] ''   1\n",
      " |GpuDot22 [id S] ''   6\n",
      " | |GpuGemm{no_inplace} [id H] ''   2\n",
      " | |GpuElemwise{mul,no_inplace} [id M] ''   5\n",
      " |TensorConstant{1.0} [id J]\n"
     ]
    }
   ],
   "source": [
    "theano.printing.debugprint(gradientDescent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__doc__',\n",
       " '__format__',\n",
       " '__getattribute__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__']"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print( gradientDescent.profile.print_summary() )\n",
    "dir( gradientDescent.profile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Linear Regression with (Batch) Gradient Descent classes in `./ML/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sys.path.append( os.getcwd() + '/ML')\n",
    "sys.path.append( os.getcwd() + '/ML' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from linreg_gradDes import LinearReg, LinearReg_loaded\n",
    "#from ML import LinearReg, LinearReg_loaded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Boilerplate** for sample input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linregdata1 = pd.read_csv('./coursera_Ng/machine-learning-ex1/ex1/ex1data1.txt', header=None)\n",
    "linregdata1.as_matrix([0]).shape\n",
    "linregdata1.as_matrix([1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = linregdata1.as_matrix([0]).shape[1]\n",
    "numberoftraining = linregdata1.as_matrix([0]).shape[0]\n",
    "LinReg_housing = LinearReg( features, numberoftraining , 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xin   = LinReg_housing.preprocess_X( linregdata1.as_matrix([0]))\n",
    "ytest = linregdata1.as_matrix([1]).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 171 ms, sys: 28.9 ms, total: 200 ms\n",
      "Wall time: 198 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-3.63029242,  1.1663624 ], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time LinReg_housing.build_model( Xin, ytest )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "LinRegloaded_housing = LinearReg_loaded( linregdata1.as_matrix([0]), linregdata1.as_matrix([1]), \n",
    "                                        features, numberoftraining )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 136 ms, sys: 16.4 ms, total: 152 ms\n",
      "Wall time: 132 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-3.63028979],\n",
       "       [ 1.16636217]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time LinRegloaded_housing.build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GpuFromHost(X), Shape_i{0}(X), GpuFromHost(y), GpuAllocEmpty(TensorConstant{1}), GpuDimShuffle{1,0}(GpuFromHost.0), GpuAllocEmpty(Shape_i{0}.0), GpuGemv{inplace}(GpuAllocEmpty.0, TensorConstant{1.0}, GpuFromHost.0, theta, TensorConstant{0.0}), GpuElemwise{Sub}[(0, 1)](GpuGemv{inplace}.0, GpuFromHost.0), GpuDimShuffle{0}(GpuElemwise{Sub}[(0, 1)].0), GpuDimShuffle{x,0}(GpuElemwise{Sub}[(0, 1)].0), GpuGemv{inplace}(GpuAllocEmpty.0, TensorConstant{1.0}, GpuDimShuffle{x,0}.0, GpuDimShuffle{0}.0, TensorConstant{0.0}), GpuElemwise{Mul}[(0, 1)](CudaNdarrayConstant{[ 0.00515464]}, GpuElemwise{Sub}[(0, 1)].0), GpuDimShuffle{}(GpuGemv{inplace}.0), GpuGemv{inplace}(theta, TensorConstant{-0.019999999553}, GpuDimShuffle{1,0}.0, GpuElemwise{Mul}[(0, 1)].0, TensorConstant{1.0}), GpuElemwise{Mul}[(0, 1)](CudaNdarrayConstant{0.00515463901684}, GpuDimShuffle{}.0)]\n",
      "[Shape_i{1}(theta), GpuDimShuffle{1,0}(X), GpuGemm{no_inplace}(y, TensorConstant{1.0}, X, theta, TensorConstant{-1.0}), MakeVector{dtype='int64'}(Shape_i{1}.0, Shape_i{1}.0), GpuReshape{2}(CudaNdarrayConstant{1.0}, MakeVector{dtype='int64'}.0), GpuElemwise{mul,no_inplace}(CudaNdarrayConstant{[[ 0.00515464]]}, GpuReshape{2}.0), GpuDot22(GpuGemm{no_inplace}.0, GpuElemwise{mul,no_inplace}.0), GpuDimShuffle{1,0}(GpuElemwise{mul,no_inplace}.0), GpuDot22(GpuGemm{no_inplace}.0, GpuDimShuffle{1,0}.0), GpuGemm{inplace}(theta, TensorConstant{-0.00999999977648}, GpuDimShuffle{1,0}.0, GpuDot22.0, TensorConstant{1.0}), GpuGemm{inplace}(GpuGemm{inplace}.0, TensorConstant{-0.00999999977648}, GpuDimShuffle{1,0}.0, GpuDot22.0, TensorConstant{1.0})]\n"
     ]
    }
   ],
   "source": [
    "print( LinReg_housing.gradientDescent.maker.fgraph.toposort() )\n",
    "print( LinRegloaded_housing.gradientDescent.maker.fgraph.toposort() )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other (sample) datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider *feature normalization*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def featureNormalize(X):\n",
    "    \"\"\"\n",
    "    FEATURENORMALIZE Normalizes the features in X  \n",
    "    FEATURENORMALIZE(X) returns a normalized version of X where  \n",
    "    the mean value of each feature is 0 and the standard deviation  \n",
    "    is 1.  This is often a good preprocessing step to do when \n",
    "    working with learning algorithms.\n",
    "    \n",
    "    \"\"\"\n",
    "    # You need to set these values correctly  \n",
    "    X_norm = (X-X.mean(axis=0))/X.std(axis=0)\n",
    "    mu = X.mean(axis=0)\n",
    "    sigma = X.std(axis=0)\n",
    "    \n",
    "    return [X_norm, mu, sigma]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "linregdata2 = pd.read_csv('./coursera_Ng/machine-learning-ex1/ex1/ex1data2.txt', header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = linregdata2.as_matrix().shape[1] - 1\n",
    "numberoftraining = linregdata2.as_matrix().shape[0]\n",
    "Xdat  = linregdata2.as_matrix( range(features) )\n",
    "ytest = linregdata2.as_matrix( [features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[Xnorm, mus,sigmas] = featureNormalize(Xdat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "LinReg_housing2 = LinearReg( features, numberoftraining, 0.01)\n",
    "processed_X = LinReg_housing2.preprocess_X( Xnorm )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 59.1 ms, sys: 8.88 ms, total: 67.9 ms\n",
      "Wall time: 66.2 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 334302.125    ,   99411.4609375,    3267.0065918], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time LinReg_housing2.build_model( processed_X, ytest.flatten(), 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "LinRegloaded_housing2 = LinearReg_loaded( Xnorm, ytest, \n",
    "                                        features, numberoftraining )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 48.9 ms, sys: 2.49 ms, total: 51.3 ms\n",
      "Wall time: 45.4 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 334302.21875   ],\n",
       "       [  99411.453125  ],\n",
       "       [   3267.00976562]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time LinRegloaded_housing2.build_model(  400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Diabetes data from `sklearn`, sci-kit learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the diabetes dataset\n",
    "diabetes = sklearn.datasets.load_diabetes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "diabetes_X = diabetes.data\n",
    "diabetes_Y = diabetes.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#diabetes_X1 = diabetes_X[:,np.newaxis,2]\n",
    "diabetes_X1 = diabetes_X[:,np.newaxis, 2].astype(theano.config.floatX)\n",
    "#diabetes_Y  = diabetes_Y.reshape( diabetes_Y.shape[0], 1)\n",
    "diabetes_Y = np.vstack( diabetes_Y.astype(theano.config.floatX) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "features1 = 1 \n",
    "numberoftraining = diabetes_Y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "LinReg_diabetes = LinearReg( features1, numberoftraining, 0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_X = LinReg_diabetes.preprocess_X( diabetes_X1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 753 ms, sys: 118 ms, total: 871 ms\n",
      "Wall time: 867 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 152.13273621,  192.24055481], dtype=float32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time LinReg_diabetes.build_model( processed_X, diabetes_Y.flatten(), 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LinRegloaded_diabetes = LinearReg_loaded( diabetes_X1, diabetes_Y, \n",
    "                                        features1, numberoftraining )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 707 ms, sys: 45.2 ms, total: 752 ms\n",
      "Wall time: 718 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 152.13198853],\n",
       "       [ 192.2406311 ]], dtype=float32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time LinRegloaded_diabetes.build_model(  10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple number of features case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = diabetes_X.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LinReg_diabetes = LinearReg( features, numberoftraining, 0.01)\n",
    "processed_X = LinReg_diabetes.preprocess_X( diabetes_X )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 855 ms, sys: 113 ms, total: 968 ms\n",
      "Wall time: 964 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 152.13273621,   40.02508163,   -5.81352949,  162.25823975,\n",
       "        117.35097504,   38.3995285 ,   24.88706589, -100.40937042,\n",
       "         99.55418396,  149.29826355,   92.1962738 ], dtype=float32)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time LinReg_diabetes.build_model( processed_X, diabetes_Y.flatten(), 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LinRegloaded_diabetes = LinearReg_loaded( diabetes_X, diabetes_Y, \n",
    "                                        features, numberoftraining )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 702 ms, sys: 64.4 ms, total: 766 ms\n",
      "Wall time: 728 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 152.13198853],\n",
       "       [  40.02506256],\n",
       "       [  -5.81354237],\n",
       "       [ 162.25799561],\n",
       "       [ 117.35108948],\n",
       "       [  38.39954376],\n",
       "       [  24.88703156],\n",
       "       [-100.40942383],\n",
       "       [  99.55430603],\n",
       "       [ 149.29826355],\n",
       "       [  92.1962738 ]], dtype=float32)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time LinRegloaded_diabetes.build_model(  10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## `ex2` Linear Regression, on d=2 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n",
      "<type 'numpy.ndarray'>\n",
      "(47, 2)\n",
      "(47, 1)\n",
      "47\n",
      "[[  2.10400000e+03   3.00000000e+00]\n",
      " [  1.60000000e+03   3.00000000e+00]\n",
      " [  2.40000000e+03   3.00000000e+00]\n",
      " [  1.41600000e+03   2.00000000e+00]\n",
      " [  3.00000000e+03   4.00000000e+00]]\n",
      "[[ 399900.]\n",
      " [ 329900.]\n",
      " [ 369000.]\n",
      " [ 232000.]\n",
      " [ 539900.]]\n"
     ]
    }
   ],
   "source": [
    "data_ex1data2 = pd.read_csv('./coursera_Ng/machine-learning-ex1/ex1/ex1data2.txt', header=None)\n",
    "X_ex1data2 = data_ex1data2.iloc[:,0:2]\n",
    "y_ex1data2 = data_ex1data2.iloc[:,2]\n",
    "m_ex1data2 = y_ex1data2.shape[0]\n",
    "X_ex1data2=X_ex1data2.values.astype(np.float32)\n",
    "y_ex1data2=y_ex1data2.values.reshape((m_ex1data2,1)).astype(np.float32)\n",
    "print(type(X_ex1data2))\n",
    "print(type(y_ex1data2))\n",
    "print(X_ex1data2.shape)\n",
    "print(y_ex1data2.shape)\n",
    "print(m_ex1data2)\n",
    "print(X_ex1data2[:5])\n",
    "print(y_ex1data2[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99999988"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((X_ex1data2[:,1] - X_ex1data2[:,1].mean())/( X_ex1data2[:,1].std()) ).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-7.10183e-08\n",
      "1.0\n",
      "2.69489e-08\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# feature Normalize\n",
    "#X_ex1data2_norm = sklearn.preprocessing.Normalizer.transform(X_ex1data2 )\n",
    "X_ex1data2_norm = (X_ex1data2  - np.mean(X_ex1data2, axis=0)) / np.std(X_ex1data2, axis=0)\n",
    "print(X_ex1data2_norm[:,0].mean())\n",
    "print(X_ex1data2_norm[:,0].std())\n",
    "print(X_ex1data2_norm[:,1].mean())\n",
    "print(X_ex1data2_norm[:,1].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_ex1data2_norm[:5];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=T.matrix(dtype=theano.config.floatX)\n",
    "y=T.matrix(dtype=theano.config.floatX)\n",
    "\n",
    "Theta=theano.shared(np.zeros((2,1)).astype(theano.config.floatX))\n",
    "b = theano.shared(np.zeros(1).astype(theano.config.floatX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,)\n"
     ]
    }
   ],
   "source": [
    "print(b.get_value().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yhat = T.dot( X, Theta) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L2 norm\n",
    "J = np.cast[theano.config.floatX](0.5)*T.mean( T.sqr( yhat-y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha=0.01  # learning rate\n",
    "# sandbox.cuda.basic_ops.gpu_from_host\n",
    "updateThetab = [ Theta-np.float32(alpha)*T.grad(J,Theta), b-np.float32(alpha)*T.grad(J,b)]\n",
    "gradientDescent_step = theano.function(inputs=[X,y], \n",
    "                                          outputs=J,\n",
    "                                          updates = zip([Theta,b],updateThetab) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iters =400\n",
    "JList=[]\n",
    "for iter in range(num_iters):\n",
    "    err = gradientDescent_step(X_ex1data2_norm,y_ex1data2)\n",
    "    JList.append(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 99411.44601356]\n",
      " [  3267.01771421]]\n",
      "[ 334302.0699632]\n"
     ]
    }
   ],
   "source": [
    "# Final mode:\n",
    "print(Theta.get_value())\n",
    "print(b.get_value())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEDCAYAAAAVyO4LAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niEjAqLhFRAJGxS0iEjD/H5Ogk2RO82SuAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fea546723d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# JList[-10:]\n",
    "plt.plot(JList)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-class Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cf. `ex3`, Programming Exercise 3: Multi-class Classification and Neural Networks, Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Multi-class Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/topolo/PropD/MLgrabbag'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ex3.pdf', 'ex3']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir( './coursera_Ng/machine-learning-ex3/' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ex3data1.mat',\n",
       " 'submit.m',\n",
       " 'sigmoid.m',\n",
       " 'lrCostFunction.m',\n",
       " 'predictOneVsAll.m',\n",
       " 'oneVsAll.m',\n",
       " 'predict.m',\n",
       " 'ex3.m',\n",
       " 'lib',\n",
       " 'displayData.m',\n",
       " 'ex3_nn.m',\n",
       " 'fmincg.m',\n",
       " 'ex3weights.mat']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir( './coursera_Ng/machine-learning-ex3/ex3' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved matrices from file \n",
    "multiclscls_data = scipy.io.loadmat('./coursera_Ng/machine-learning-ex3/ex3/ex3data1.mat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import the classes from `ML`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/topolo/PropD/MLgrabbag'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sys.path.append( os.getcwd() + '/ML')\n",
    "sys.path.append( os.getcwd() + '/ML' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gradDes import LogReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test case for Cost function J_{\\theta} with regularization\n",
    "\n",
    "theta_t = np.vstack( np.array( [-2, -1, 1, 2]) )\n",
    "X_t = np.array( [i/10. for i in range(1,16)]).reshape((3,5)).T\n",
    "#X_t = np.hstack( ( np.ones((5,1)), X_t) ) # no need to preprocess the input data X with column of 1's\n",
    "y_t = np.vstack( np.array( [1,0,1,0,1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "MulClsCls_digits = LogReg( X_t, y_t, 3,5,0.01, 3.  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CudaNdarray(0.125)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MulClsCls_digits.calculate_cost()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CudaNdarrayVariable' object has no attribute 'get_value'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-f79030e398ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mMulClsCls_digits\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'CudaNdarrayVariable' object has no attribute 'get_value'"
     ]
    }
   ],
   "source": [
    "MulClsCls_digits.z.get_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          0.1         0.60000002  1.10000002]\n",
      " [ 1.          0.2         0.69999999  1.20000005]\n",
      " [ 1.          0.30000001  0.80000001  1.29999995]\n",
      " [ 1.          0.40000001  0.89999998  1.39999998]\n",
      " [ 1.          0.5         1.          1.5       ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.],\n",
       "       [ 0.],\n",
       "       [ 1.],\n",
       "       [ 0.],\n",
       "       [ 1.]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print( MulClsCls_digits.X.get_value() )\n",
    "MulClsCls_digits.y.get_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_z_test = theano.function([], MulClsCls_digits.z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CudaNdarray([[ 0.]\n",
       " [ 0.]\n",
       " [ 0.]\n",
       " [ 0.]\n",
       " [ 0.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_z_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MulClsCls_digits.theta.set_value( theta_t.astype('float32') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CudaNdarray([[ 0.70000017]\n",
       " [ 0.9000001 ]\n",
       " [ 1.0999999 ]\n",
       " [ 1.29999983]\n",
       " [ 1.5       ]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_z_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CudaNdarray(1.93287348747)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MulClsCls_digits.calculate_cost()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.66818777]\n",
      " [ 0.7109495 ]\n",
      " [ 0.75026011]\n",
      " [ 0.78583498]\n",
      " [ 0.81757448]]\n",
      "[[ 0.13287343]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.8]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print( 1/(1+np.exp( np.dot( -np.hstack( ( np.ones((5,1)), X_t) ), theta_t) ) )  )\n",
    "h_test = 1/(1+np.exp( np.dot( -np.hstack( ( np.ones((5,1)), X_t) ), theta_t) ) ) \n",
    "print( np.dot( (h_test - y_t).T, h_test- y_t) * 0.5/5 ) # non-regularized J_theta cost term\n",
    "np.dot( theta_t[1:].T, theta_t[1:]) * 3 / (2.* 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.66818786],\n",
       "       [ 0.71094954],\n",
       "       [ 0.75026011],\n",
       "       [ 0.78583503],\n",
       "       [ 0.81757444]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MulClsCls_digits.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MulClsCls_digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'float32'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theano.config.floatX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cf. 2 Neural Networks, 2.1 Model representation, `ex3.pdf`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/topolo/PropD/MLgrabbag'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ex3.pdf', 'ex3']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir( './coursera_Ng/machine-learning-ex3/' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ex3data1.mat',\n",
       " 'submit.m',\n",
       " 'sigmoid.m',\n",
       " 'token.mat',\n",
       " 'lrCostFunction.m',\n",
       " 'predictOneVsAll.m',\n",
       " 'oneVsAll.m',\n",
       " 'predict.m',\n",
       " 'ex3.m',\n",
       " 'lib',\n",
       " 'displayData.m',\n",
       " 'ex3_nn.m',\n",
       " 'fmincg.m',\n",
       " 'ex3weights.mat']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir( './coursera_Ng/machine-learning-ex3/ex3/' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\Theta_1, \\Theta_2 $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load saved matrices from file \n",
    "nn3_data = scipy.io.loadmat('./coursera_Ng/machine-learning-ex3/ex3/ex3weights.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Theta2', '__version__', '__header__', 'Theta1', '__globals__']\n",
      "<type 'numpy.ndarray'>\n",
      "<type 'numpy.ndarray'>\n",
      "(25, 401)\n",
      "(10, 26)\n"
     ]
    }
   ],
   "source": [
    "print( nn3_data.keys() )\n",
    "print( type( nn3_data['Theta1']) )\n",
    "print( type( nn3_data['Theta2']) )\n",
    "print( nn3_data['Theta1'].shape )\n",
    "print( nn3_data['Theta2'].shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Theta1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-ff0b751d0b88>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mTheta1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Theta1' is not defined"
     ]
    }
   ],
   "source": [
    "Theta1[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedforward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named tikzmagic",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-445a5d6380b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'load_ext tikzmagic'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/topolo/Public/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mmagic\u001b[1;34m(self, arg_s)\u001b[0m\n\u001b[0;32m   2161\u001b[0m         \u001b[0mmagic_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg_s\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2162\u001b[0m         \u001b[0mmagic_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefilter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mESC_MAGIC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2163\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2165\u001b[0m     \u001b[1;31m#-------------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/topolo/Public/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_line_magic\u001b[1;34m(self, magic_name, line)\u001b[0m\n\u001b[0;32m   2082\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'local_ns'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2083\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2084\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2085\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2086\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-64>\u001b[0m in \u001b[0;36mload_ext\u001b[1;34m(self, module_str)\u001b[0m\n",
      "\u001b[1;32m/home/topolo/Public/anaconda2/lib/python2.7/site-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/topolo/Public/anaconda2/lib/python2.7/site-packages/IPython/core/magics/extension.pyc\u001b[0m in \u001b[0;36mload_ext\u001b[1;34m(self, module_str)\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmodule_str\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mUsageError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Missing module name.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextension_manager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_extension\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'already loaded'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/topolo/Public/anaconda2/lib/python2.7/site-packages/IPython/core/extensions.pyc\u001b[0m in \u001b[0;36mload_extension\u001b[1;34m(self, module_str)\u001b[0m\n\u001b[0;32m     82\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmodule_str\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mprepended_to_syspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mipython_extension_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m                     \u001b[0m__import__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m             \u001b[0mmod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodule_str\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_load_ipython_extension\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named tikzmagic"
     ]
    }
   ],
   "source": [
    "%load_ext tikzmagic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$  \n",
    "\\begin{tikzpicture}\n",
    "  \\matrix (m) [matrix of math nodes, row sep=3em, column sep=4em, minimum width=2em]\n",
    "  {\n",
    "    \\mathbb{R}^{s_l}  &  \\mathbb{R}^{ s_l +1 }   & \\mathbb{R}^{s_{l+1} } & \\mathbb{R}^{s_{l+1} }  \\\\\n",
    "a^{(l)} & (a_0^{(l)} = 1, a^{(l)} ) & z^{(l+1)} & g(z^{(l+1)}) = a^{(l+1)} \\\\\n",
    "  };\n",
    "  \\path[->]\n",
    "  (m-1-1) edge node [above] {$a_0^{(l)}=1$} (m-1-2)\n",
    "  (m-1-2) edge node [above] {$\\Theta^{(l)}$} (m-1-3)\n",
    "  (m-1-3) edge node [above] {$g$} (m-1-4) \n",
    "  ;\n",
    "  \\path[|->]\n",
    "  (m-2-1) edge node [above] {$a_0^{(l)}=1$} (m-2-2)\n",
    "  (m-2-2) edge node [above] {$\\Theta^{(l)}$} (m-2-3)\n",
    "  (m-2-3) edge node [above] {$g$} (m-2-4) \n",
    "  ;\n",
    "\\end{tikzpicture}  \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Cuda error 'unspecified launch failure' while copying %lli data element to device memory",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-ca1c7934296c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0ms_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m400\u001b[0m \u001b[1;31m# (layer) size of layer l, i.e. number of nodes, units in layer l\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0ms_lp1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m25\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshared\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms_l\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'float32'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"al\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;31m#alp1 = theano.shared( np.random.randn(s_lp1,1).astype('float32'), name=\"al\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#Thetal = theano.shared( np.random.randn( s_lp1,s_l+1).astype('float32') , name=\"Thetal\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/topolo/Public/anaconda2/lib/python2.7/site-packages/theano/compile/sharedvalue.pyc\u001b[0m in \u001b[0;36mshared\u001b[1;34m(value, name, strict, allow_downcast, **kwargs)\u001b[0m\n\u001b[0;32m    245\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m                 var = ctor(value, name=name, strict=strict,\n\u001b[1;32m--> 247\u001b[1;33m                            allow_downcast=allow_downcast, **kwargs)\n\u001b[0m\u001b[0;32m    248\u001b[0m                 \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_tag_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mvar\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/topolo/Public/anaconda2/lib/python2.7/site-packages/theano/sandbox/cuda/var.pyc\u001b[0m in \u001b[0;36mfloat32_shared_constructor\u001b[1;34m(value, name, strict, allow_downcast, borrow, broadcastable, target)\u001b[0m\n\u001b[0;32m    238\u001b[0m         \u001b[1;31m# type.broadcastable is guaranteed to be a tuple, which this next\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m         \u001b[1;31m# function requires\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 240\u001b[1;33m         \u001b[0mdeviceval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_support_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbroadcastable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Cuda error 'unspecified launch failure' while copying %lli data element to device memory"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "s_l = 400 # (layer) size of layer l, i.e. number of nodes, units in layer l\n",
    "s_lp1 = 25\n",
    "al = theano.shared( np.random.randn(s_l+1,1).astype('float32'), name=\"al\")\n",
    "#alp1 = theano.shared( np.random.randn(s_lp1,1).astype('float32'), name=\"al\")\n",
    "#Thetal = theano.shared( np.random.randn( s_lp1,s_l+1).astype('float32') , name=\"Thetal\")\n",
    "\n",
    "# Feedforward, forward propagation\n",
    "#z = T.dot( Thetal, al)\n",
    "#g = T.nnet.sigmoid( z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s_l = 25\n",
    "s_lp1 = 10\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 26)\n",
      "float32\n",
      "float32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10, 26)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = np.random.RandomState(99)\n",
    "Theta_values = np.asarray( rng.uniform( \n",
    "    low=-np.sqrt( 6. / (s_l+ s_lp1)), \n",
    "    high=np.sqrt( 6./(s_l + s_lp1)), size=(s_lp1,s_l+1)), dtype=theano.config.floatX )\n",
    "print( Theta_values.shape )\n",
    "print( Theta_values.dtype )\n",
    "#Theta_values *= np.float32(4)\n",
    "Theta_values *= 4.\n",
    "\n",
    "print( Theta_values.dtype)\n",
    "Theta_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 26)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.float32( 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From Deep Learning Tutorials of LISA lab of University of Montreal; `logistic_sgd.py`, `mlp.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BASH_FUNC_module()': '() {  eval `/usr/bin/modulecmd bash $*`\\n}',\n",
       " 'BASH_FUNC_scl()': '() {  local CMD=$1;\\n if [ \"$CMD\" = \"load\" -o \"$CMD\" = \"unload\" ]; then\\n eval \"module $@\";\\n else\\n /usr/bin/scl \"$@\";\\n fi\\n}',\n",
       " 'CLICOLOR': '1',\n",
       " 'CVS_RSH': 'ssh',\n",
       " 'DBUS_SESSION_BUS_ADDRESS': 'unix:abstract=/tmp/dbus-N7ppIfAX8e,guid=e833f00fdfe69074bad66b6a58a4c651',\n",
       " 'DESKTOP_SESSION': 'gnome',\n",
       " 'DISPLAY': ':1',\n",
       " 'GDMSESSION': 'gnome',\n",
       " 'GDM_LANG': 'en_US.UTF-8',\n",
       " 'GIT_PAGER': 'cat',\n",
       " 'GJS_DEBUG_OUTPUT': 'stderr',\n",
       " 'GJS_DEBUG_TOPICS': 'JS ERROR;JS LOG',\n",
       " 'GNOME_DESKTOP_SESSION_ID': 'this-is-deprecated',\n",
       " 'HISTCONTROL': 'ignoredups',\n",
       " 'HISTSIZE': '1000',\n",
       " 'HOME': '/home/topolo',\n",
       " 'HOSTNAME': 'localhost.localdomain',\n",
       " 'JPY_PARENT_PID': '3902',\n",
       " 'LANG': 'en_US.UTF-8',\n",
       " 'LD_LIBRARY_PATH': '/usr/local/lib:/usr/local/lib::/usr/local/cuda/lib64:/usr/local/lib64:/usr/local/cuda/lib64:/usr/local/lib64',\n",
       " 'LESSOPEN': '||/usr/bin/lesspipe.sh %s',\n",
       " 'LOADEDMODULES': '',\n",
       " 'LOGNAME': 'topolo',\n",
       " 'LS_COLORS': 'rs=0:di=38;5;33:ln=38;5;51:mh=00:pi=40;38;5;11:so=38;5;13:do=38;5;5:bd=48;5;232;38;5;11:cd=48;5;232;38;5;3:or=48;5;232;38;5;9:mi=01;05;37;41:su=48;5;196;38;5;15:sg=48;5;11;38;5;16:ca=48;5;196;38;5;226:tw=48;5;10;38;5;16:ow=48;5;10;38;5;21:st=48;5;21;38;5;15:ex=38;5;40:*.tar=38;5;9:*.tgz=38;5;9:*.arc=38;5;9:*.arj=38;5;9:*.taz=38;5;9:*.lha=38;5;9:*.lz4=38;5;9:*.lzh=38;5;9:*.lzma=38;5;9:*.tlz=38;5;9:*.txz=38;5;9:*.tzo=38;5;9:*.t7z=38;5;9:*.zip=38;5;9:*.z=38;5;9:*.Z=38;5;9:*.dz=38;5;9:*.gz=38;5;9:*.lrz=38;5;9:*.lz=38;5;9:*.lzo=38;5;9:*.xz=38;5;9:*.bz2=38;5;9:*.bz=38;5;9:*.tbz=38;5;9:*.tbz2=38;5;9:*.tz=38;5;9:*.deb=38;5;9:*.rpm=38;5;9:*.jar=38;5;9:*.war=38;5;9:*.ear=38;5;9:*.sar=38;5;9:*.rar=38;5;9:*.alz=38;5;9:*.ace=38;5;9:*.zoo=38;5;9:*.cpio=38;5;9:*.7z=38;5;9:*.rz=38;5;9:*.cab=38;5;9:*.jpg=38;5;13:*.jpeg=38;5;13:*.gif=38;5;13:*.bmp=38;5;13:*.pbm=38;5;13:*.pgm=38;5;13:*.ppm=38;5;13:*.tga=38;5;13:*.xbm=38;5;13:*.xpm=38;5;13:*.tif=38;5;13:*.tiff=38;5;13:*.png=38;5;13:*.svg=38;5;13:*.svgz=38;5;13:*.mng=38;5;13:*.pcx=38;5;13:*.mov=38;5;13:*.mpg=38;5;13:*.mpeg=38;5;13:*.m2v=38;5;13:*.mkv=38;5;13:*.webm=38;5;13:*.ogm=38;5;13:*.mp4=38;5;13:*.m4v=38;5;13:*.mp4v=38;5;13:*.vob=38;5;13:*.qt=38;5;13:*.nuv=38;5;13:*.wmv=38;5;13:*.asf=38;5;13:*.rm=38;5;13:*.rmvb=38;5;13:*.flc=38;5;13:*.avi=38;5;13:*.fli=38;5;13:*.flv=38;5;13:*.gl=38;5;13:*.dl=38;5;13:*.xcf=38;5;13:*.xwd=38;5;13:*.yuv=38;5;13:*.cgm=38;5;13:*.emf=38;5;13:*.ogv=38;5;13:*.ogx=38;5;13:*.aac=38;5;45:*.au=38;5;45:*.flac=38;5;45:*.m4a=38;5;45:*.mid=38;5;45:*.midi=38;5;45:*.mka=38;5;45:*.mp3=38;5;45:*.mpc=38;5;45:*.ogg=38;5;45:*.ra=38;5;45:*.wav=38;5;45:*.oga=38;5;45:*.opus=38;5;45:*.spx=38;5;45:*.xspf=38;5;45:',\n",
       " 'MAIL': '/var/spool/mail/topolo',\n",
       " 'MODULEPATH': '/etc/scl/modulefiles:/etc/scl/modulefiles:/usr/share/Modules/modulefiles:/etc/modulefiles:/usr/share/modulefiles',\n",
       " 'MODULESHOME': '/usr/share/Modules',\n",
       " 'OLDPWD': '/',\n",
       " 'PAGER': 'cat',\n",
       " 'PATH': '/usr/local/cuda-7.5/bin:/home/topolo/Public/anaconda2/bin:/usr/local/cuda-7.5/bin:/home/topolo/Public/anaconda2/bin:/usr/local/bin:/usr/local/sbin:/usr/bin:/usr/sbin:/home/topolo/.local/bin:/home/topolo/bin',\n",
       " 'PWD': '/home/topolo',\n",
       " 'QT_IM_MODULE': 'ibus',\n",
       " 'SESSION_MANAGER': 'local/unix:@/tmp/.ICE-unix/2593,unix/unix:/tmp/.ICE-unix/2593',\n",
       " 'SHELL': '/bin/bash',\n",
       " 'SHLVL': '2',\n",
       " 'SSH_ASKPASS': '/usr/libexec/openssh/gnome-ssh-askpass',\n",
       " 'SSH_AUTH_SOCK': '/run/user/1001/keyring/ssh',\n",
       " 'TERM': 'xterm-color',\n",
       " 'THEANO_FLAGS': 'mode=FAST_RUN,floatX=float32,device=gpu0,lib.cnmem=0.80',\n",
       " 'USER': 'topolo',\n",
       " 'USERNAME': 'topolo',\n",
       " 'VTE_VERSION': '4205',\n",
       " 'WINDOWID': '29360134',\n",
       " 'WINDOWPATH': '2',\n",
       " 'XAUTHORITY': '/run/user/1001/gdm/Xauthority',\n",
       " 'XDG_CURRENT_DESKTOP': 'GNOME',\n",
       " 'XDG_MENU_PREFIX': 'gnome-',\n",
       " 'XDG_RUNTIME_DIR': '/run/user/1001',\n",
       " 'XDG_SEAT': 'seat0',\n",
       " 'XDG_SESSION_DESKTOP': 'gnome',\n",
       " 'XDG_SESSION_ID': '1',\n",
       " 'XDG_SESSION_TYPE': 'x11',\n",
       " 'XDG_VTNR': '2',\n",
       " 'XMODIFIERS': '@im=ibus',\n",
       " '_': '/home/topolo/Public/anaconda2/bin/jupyter'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/topolo/PropD/MLgrabbag'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '/home/topolo/Public/anaconda2/lib/python2.7/site-packages/thermopy-0.5.4-py2.7.egg', '/home/topolo/Public/anaconda2/lib/python2.7/site-packages/pytools-2016.2.6-py2.7.egg', '/home/topolo/Public/anaconda2/lib/python2.7/site-packages/appdirs-1.4.0-py2.7.egg', '/home/topolo/Public/anaconda2/lib/python27.zip', '/home/topolo/Public/anaconda2/lib/python2.7', '/home/topolo/Public/anaconda2/lib/python2.7/plat-linux2', '/home/topolo/Public/anaconda2/lib/python2.7/lib-tk', '/home/topolo/Public/anaconda2/lib/python2.7/lib-old', '/home/topolo/Public/anaconda2/lib/python2.7/lib-dynload', '/home/topolo/Public/anaconda2/lib/python2.7/site-packages/PyDispatcher-2.0.5-py2.7.egg', '/home/topolo/Public/anaconda2/lib/python2.7/site-packages/Sphinx-1.3.5-py2.7.egg', '/home/topolo/Public/anaconda2/lib/python2.7/site-packages/characteristic-14.3.0-py2.7.egg', '/home/topolo/Public/anaconda2/lib/python2.7/site-packages/cssselect-0.9.1-py2.7.egg', '/home/topolo/Public/anaconda2/lib/python2.7/site-packages/pyasn1_modules-0.0.5-py2.7.egg', '/home/topolo/Public/anaconda2/lib/python2.7/site-packages/service_identity-14.0.0-py2.7.egg', '/home/topolo/Public/anaconda2/lib/python2.7/site-packages/setuptools-20.3-py2.7.egg', '/home/topolo/Public/anaconda2/lib/python2.7/site-packages', '/home/topolo/Public/anaconda2/lib/python2.7/site-packages/IPython/extensions', '/home/topolo/.ipython']\n"
     ]
    }
   ],
   "source": [
    "print( sys.path )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sys.path.append( os.getcwd() + '/ML')\n",
    "sys.path.append( '../DeepLearningTutorials/code/' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from logistic_sgd import LogisticRegression, load_data, sgd_optimization_mnist, predict\n",
    "import logistic_sgd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'logistic_sgd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-1526aa8fd8a5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mMNIST_MTLdat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogistic_sgd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../DeepLearningTutorials/data/mnist.pkl.gz\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# list of training data\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'logistic_sgd' is not defined"
     ]
    }
   ],
   "source": [
    "MNIST_MTLdat = logistic_sgd.load_data(\"../DeepLearningTutorials/data/mnist.pkl.gz\") # list of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "<type 'list'>\n",
      "<type 'tuple'> 2\n",
      "<type 'tuple'> 2\n",
      "<type 'tuple'> 2\n"
     ]
    }
   ],
   "source": [
    "print(len(MNIST_MTLdat))\n",
    "print(type(MNIST_MTLdat))\n",
    "for ele in MNIST_MTLdat: print type(ele), len(ele) # test_set_x, test_set_y, valid_set_x, valid_set_y, train_set_x, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784)\n",
      "<class 'theano.tensor.var.TensorVariable'>\n",
      "<bound method TensorVariable.get_scalar_constant_value of Elemwise{Cast{int32}}.0>\n"
     ]
    }
   ],
   "source": [
    "print( MNIST_MTLdat[0][0].get_value().shape)\n",
    "print( type(MNIST_MTLdat[0][1]))\n",
    "print( MNIST_MTLdat[0][1].get_scalar_constant_value )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'theano.tensor.var.TensorVariable'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Shape.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print( type( MNIST_MTLdat[1][1] ) )\n",
    "MNIST_MTLdat[1][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(MNIST_MTLdat[0][1]) ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import six.moves.cPickle as pickle\n",
    "with gzip.open(\"../DeepLearningTutorials/data/mnist.pkl.gz\", 'rb') as f:\n",
    "    try:\n",
    "        train_set, valid_set, test_set = pickle.load(f, encoding='latin1')\n",
    "    except:\n",
    "        train_set, valid_set, test_set = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n",
      "(50000, 784)\n",
      "<type 'numpy.ndarray'>\n",
      "(50000,)\n",
      "<type 'numpy.ndarray'>\n",
      "(10000, 784)\n",
      "<type 'numpy.ndarray'>\n",
      "(10000,)\n",
      "<type 'numpy.ndarray'>\n",
      "(10000, 784)\n",
      "<type 'numpy.ndarray'>\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print( type( train_set[0] ))\n",
    "print( train_set[0].shape )\n",
    "print( type( train_set[1]))\n",
    "print( train_set[1].shape )\n",
    "print( type( valid_set[0] ))\n",
    "print( valid_set[0].shape )\n",
    "print( type( valid_set[1]))\n",
    "print( valid_set[1].shape )\n",
    "print( type( test_set[0] ))\n",
    "print( test_set[0].shape )\n",
    "print( type( test_set[1]))\n",
    "print( test_set[1].shape )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_set[0].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>774</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>50000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000739</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022778</td>\n",
       "      <td>0.015422</td>\n",
       "      <td>0.012079</td>\n",
       "      <td>0.007217</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.001483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.988281</td>\n",
       "      <td>0.988281</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.242188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0        1        2        3        4        5        6        7    \\\n",
       "count  50000.0  50000.0  50000.0  50000.0  50000.0  50000.0  50000.0  50000.0   \n",
       "mean       0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "std        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "min        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "25%        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "50%        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "75%        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "max        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "           8        9     ...              774           775           776  \\\n",
       "count  50000.0  50000.0   ...     50000.000000  50000.000000  50000.000000   \n",
       "mean       0.0      0.0   ...         0.000739      0.000354      0.000204   \n",
       "std        0.0      0.0   ...         0.022778      0.015422      0.012079   \n",
       "min        0.0      0.0   ...         0.000000      0.000000      0.000000   \n",
       "25%        0.0      0.0   ...         0.000000      0.000000      0.000000   \n",
       "50%        0.0      0.0   ...         0.000000      0.000000      0.000000   \n",
       "75%        0.0      0.0   ...         0.000000      0.000000      0.000000   \n",
       "max        0.0      0.0   ...         0.992188      0.992188      0.988281   \n",
       "\n",
       "                777           778           779      780      781      782  \\\n",
       "count  50000.000000  50000.000000  50000.000000  50000.0  50000.0  50000.0   \n",
       "mean       0.000090      0.000071      0.000009      0.0      0.0      0.0   \n",
       "std        0.007217      0.007181      0.001483      0.0      0.0      0.0   \n",
       "min        0.000000      0.000000      0.000000      0.0      0.0      0.0   \n",
       "25%        0.000000      0.000000      0.000000      0.0      0.0      0.0   \n",
       "50%        0.000000      0.000000      0.000000      0.0      0.0      0.0   \n",
       "75%        0.000000      0.000000      0.000000      0.0      0.0      0.0   \n",
       "max        0.988281      0.992188      0.242188      0.0      0.0      0.0   \n",
       "\n",
       "           783  \n",
       "count  50000.0  \n",
       "mean       0.0  \n",
       "std        0.0  \n",
       "min        0.0  \n",
       "25%        0.0  \n",
       "50%        0.0  \n",
       "75%        0.0  \n",
       "max        0.0  \n",
       "\n",
       "[8 rows x 784 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X.T).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_i = theano.shared( X.astype(\"float32\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = X_i.get_value().shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = T.stack( [ theano.shared( np.ones((1,m)).astype(\"float32\") ) , X_i ] , axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'theano.tensor.var.TensorVariable'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Join(TensorConstant{2}, DimShuffle{0,1,x}.0, DimShuffle{0,1,x}.0)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print( type(a1) )\n",
    "#print( a1.get_scalar_constant_value() )\n",
    "dir(a1)\n",
    "a1.get_parents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a1_0 = theano.shared( np.ones((1,m)).astype(\"float32\"),name='a1_0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = T.stack( [a1_0,X_i], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = X_i.get_value().shape[0]\n",
    "s_2 = d/2\n",
    "rng1 = np.random.RandomState(1234)\n",
    "Theta1_values = np.asarray( rng1.uniform( low=-np.sqrt(6./(d+s_2)),high=np.sqrt(6./(d+s_2)),size=(s_2,d+1)),\n",
    "                           dtype=theano.config.floatX)\n",
    "Theta1 = theano.shared(value=Theta1_values, name=\"Theta\",borrow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rng1.uniform( low=-np.sqrt(6./(d+s_2)),high=np.sqrt(6./(d+s_2)),size=(s_2,d+1))\n",
    "z1 = T.dot( Theta1, a1)\n",
    "a2 = T.tanh(z1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "passthru1 = theano.function( [], a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "GpuJoin: Wrong inputs for input 0 related to inputs 0.!\nApply node that caused the error: GpuJoin(TensorConstant{2}, GpuDimShuffle{0,1,x}.0, GpuDimShuffle{0,1,x}.0)\nToposort index: 9\nInputs types: [TensorType(int8, scalar), CudaNdarrayType(float32, (False, False, True)), CudaNdarrayType(float32, (False, False, True))]\nInputs shapes: [(), (1, 50000, 1), (784, 50000, 1)]\nInputs strides: [(), (0, 1, 0), (50000, 1, 0)]\nInputs values: [array(2, dtype=int8), 'not shown', 'not shown']\nOutputs clients: [[GpuDimShuffle{1,0,2}(GpuJoin.0)]]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-101-eaf6b97a7ef3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpassthru1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/topolo/Public/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    869\u001b[0m                     \u001b[0mnode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m                     \u001b[0mthunk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mthunk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 871\u001b[1;33m                     storage_map=getattr(self.fn, 'storage_map', None))\n\u001b[0m\u001b[0;32m    872\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    873\u001b[0m                 \u001b[1;31m# old-style linkers raise their own exceptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/topolo/Public/anaconda2/lib/python2.7/site-packages/theano/gof/link.pyc\u001b[0m in \u001b[0;36mraise_with_op\u001b[1;34m(node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[0;32m    312\u001b[0m         \u001b[1;31m# extra long error message in that case.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m     \u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/topolo/Public/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: GpuJoin: Wrong inputs for input 0 related to inputs 0.!\nApply node that caused the error: GpuJoin(TensorConstant{2}, GpuDimShuffle{0,1,x}.0, GpuDimShuffle{0,1,x}.0)\nToposort index: 9\nInputs types: [TensorType(int8, scalar), CudaNdarrayType(float32, (False, False, True)), CudaNdarrayType(float32, (False, False, True))]\nInputs shapes: [(), (1, 50000, 1), (784, 50000, 1)]\nInputs strides: [(), (0, 1, 0), (50000, 1, 0)]\nInputs values: [array(2, dtype=int8), 'not shown', 'not shown']\nOutputs clients: [[GpuDimShuffle{1,0,2}(GpuJoin.0)]]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node."
     ]
    }
   ],
   "source": [
    "print(d)\n",
    "passthru1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 50000)\n",
      "50000\n",
      "(1, 50000)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "X_i = theano.shared( X.astype(\"float32\"))\n",
    "#m = X_i.get_value().shape[1]\n",
    "m = X.shape[1]\n",
    "print(m)\n",
    "a1_0 = theano.shared( np.ones((1,m)).astype(\"float32\"),name='a1_0')\n",
    "print(a1_0.get_value().shape)\n",
    "a1 = T.stack( [a1_0,X_i], axis=0)\n",
    "addintercept = theano.function([],a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "GpuJoin: Wrong inputs for input 1 related to inputs 0.!\nApply node that caused the error: GpuJoin(TensorConstant{0}, GpuDimShuffle{x,0,1}.0, GpuDimShuffle{x,0,1}.0)\nToposort index: 2\nInputs types: [TensorType(int8, scalar), CudaNdarrayType(float32, (True, False, False)), CudaNdarrayType(float32, (True, False, False))]\nInputs shapes: [(), (1, 1, 50000), (1, 784, 50000)]\nInputs strides: [(), (0, 0, 1), (0, 50000, 1)]\nInputs values: [array(0, dtype=int8), 'not shown', 'not shown']\nOutputs clients: [[HostFromGpu(GpuJoin.0)]]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-109-f3e06b86efb8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0maddintercept\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/topolo/Public/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    869\u001b[0m                     \u001b[0mnode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m                     \u001b[0mthunk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mthunk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 871\u001b[1;33m                     storage_map=getattr(self.fn, 'storage_map', None))\n\u001b[0m\u001b[0;32m    872\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    873\u001b[0m                 \u001b[1;31m# old-style linkers raise their own exceptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/topolo/Public/anaconda2/lib/python2.7/site-packages/theano/gof/link.pyc\u001b[0m in \u001b[0;36mraise_with_op\u001b[1;34m(node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[0;32m    312\u001b[0m         \u001b[1;31m# extra long error message in that case.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m     \u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/topolo/Public/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: GpuJoin: Wrong inputs for input 1 related to inputs 0.!\nApply node that caused the error: GpuJoin(TensorConstant{0}, GpuDimShuffle{x,0,1}.0, GpuDimShuffle{x,0,1}.0)\nToposort index: 2\nInputs types: [TensorType(int8, scalar), CudaNdarrayType(float32, (True, False, False)), CudaNdarrayType(float32, (True, False, False))]\nInputs shapes: [(), (1, 1, 50000), (1, 784, 50000)]\nInputs strides: [(), (0, 0, 1), (0, 50000, 1)]\nInputs values: [array(0, dtype=int8), 'not shown', 'not shown']\nOutputs clients: [[HostFromGpu(GpuJoin.0)]]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node."
     ]
    }
   ],
   "source": [
    "addintercept()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784\n",
      "392\n"
     ]
    }
   ],
   "source": [
    "d = X_i.get_value().shape[0]\n",
    "print(d)\n",
    "s_2 = d/2\n",
    "print(s_2)\n",
    "rng1 = np.random.RandomState(1234)\n",
    "Theta1_values = np.asarray( rng1.uniform( low=-np.sqrt(6./(d+s_2)),high=np.sqrt(6./(d+s_2)),size=(s_2,d)),\n",
    "                           dtype=theano.config.floatX)\n",
    "Theta1 = theano.shared(value=Theta1_values, name=\"Theta1\",borrow=True)\n",
    "b_values = np.vstack( np.zeros(s_2) ).astype(theano.config.floatX)\n",
    "b1 = theano.shared(value=b_values, name='b1',borrow=True)\n",
    "a1_values=np.array( np.zeros( (d,m)), dtype=theano.config.floatX)\n",
    "a1 = theano.shared(value=a1_values, name='a1', borrow=True)\n",
    "lin_z2 = T.dot( Theta1, a1) + T.tile(b1,(1,m))\n",
    "#lin_z2 = T.dot( Theta1, a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mult = theano.function([],lin_z2)\n",
    "\n",
    "print( type(b_values))\n",
    "b_values.dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mult()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(392, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reshape{2}.0"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print( b1.get_value().shape )\n",
    "T.tile( b1, (0,m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### `NN.py`, load `NN.py` for `Layer` class for Neural Net for Multiple Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sys.path.append( os.getcwd() + '/ML')\n",
    "sys.path.append( os.getcwd() + '/ML' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NN import Layer, cost_functional, cost_functional_noreg, gradientDescent_step\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boilerplate sample data, from Coursera's *Machine Learning Introduction*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and Visualizing Data ... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load Training Data\n",
    "print(\"Loading and Visualizing Data ... \\n\")\n",
    "ex4data1 = scipy.io.loadmat('./coursera_Ng/machine-learning-ex4/ex4/ex4data1.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y', 'X', '__version__', '__header__', '__globals__']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex4data1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 400)\n",
      "(5000, 1)\n"
     ]
    }
   ],
   "source": [
    "print( ex4data1['X'].shape )\n",
    "print( ex4data1['y'].shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_rng = np.random.RandomState(1234)\n",
    "#Theta1 = Layer( test_rng, 1, 400,25, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(Theta1.al.set_value); # Beginning with Theano 0.3.1, set_value will work in-place on the GPU, if ... source on CPU\n",
    "Theta1.al.set_value( ex4data1['X'].T.astype(theano.config.floatX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Elemwise{tanh,no_inplace}.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Theta1.alp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'theano.tensor.var.TensorVariable'>\n"
     ]
    }
   ],
   "source": [
    "print( type( Theta1.alp1 ) )\n",
    "Theta2 = Layer( test_rng, 2, 25,10,5000, al=Theta1.alp1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Elemwise{tanh,no_inplace}.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Theta2.alp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = theano.function([],sandbox.cuda.basic_ops.gpu_from_host( Theta2.alp1 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 5000)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.872569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "count  5000.000000\n",
       "mean      5.500000\n",
       "std       2.872569\n",
       "min       1.000000\n",
       "25%       3.000000\n",
       "50%       5.500000\n",
       "75%       8.000000\n",
       "max      10.000000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print( ex4data1['y'].shape )\n",
    "pd.DataFrame( ex4data1['y']).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 5000)\n"
     ]
    }
   ],
   "source": [
    "# recall that whereas the original labels (in the variable y) were 1, 2, ..., 10, for the purpose of training a \n",
    "# neural network, we need to recode the labels as vectors containing only values 0 or 1\n",
    "K=10\n",
    "m = ex4data1['y'].shape[0]\n",
    "y_prob = [np.zeros(K) for row in ex4data1['y']]  # list of 5000 numpy arrays of size dims. (10,)\n",
    "for i in range( m):\n",
    "        y_prob[i][ ex4data1['y'][i]-1] = 1\n",
    "y_prob = np.array(y_prob).T.astype(theano.config.floatX)  # size dims. (K,m)\n",
    "print(y_prob.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print( type(y_prob) )\n",
    "type( np.asarray( y_prob, dtype=theano.config.floatX) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function trace in module theano.tensor.nlinalg:\n",
      "\n",
      "trace(X)\n",
      "    Returns the sum of diagonal elements of matrix X.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    Works on GPU since 0.6rc4.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help( T.nlinalg.trace )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_sh_var = theano.shared( np.asarray( y_prob,dtype=theano.config.floatX),name='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h_test = Theta2.alp1\n",
    "J = sandbox.cuda.basic_ops.gpu_from_host(\n",
    "        (-T.nlinalg.trace( T.dot( T.log( h_test ), y_sh_var.T)) - T.nlinalg.trace( \n",
    "        T.dot( T.log( np.float32(1.)-h_test),(np.float32(1.)- y_sh_var.T ) )))/np.float32(m)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'theano.sandbox.cuda.var.CudaNdarrayVariable'>\n"
     ]
    }
   ],
   "source": [
    "print(type(J))\n",
    "test_cost_func = theano.function([],J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CudaNdarray(nan)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cost_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "J_test_build = sandbox.cuda.basic_ops.gpu_from_host( -T.nlinalg.trace( T.dot( T.log(h_test),y_sh_var.T) ) )\n",
    "test_cost_build_func = theano.function([], J_test_build)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CudaNdarray(nan)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cost_build_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Sanity check using `ex4.m`, Exercise 4 or Programming Exercise 4 from Coursera's Machine Learning Introduction by Ng ** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Theta_testvals = scipy.io.loadmat('./coursera_Ng/machine-learning-ex4/ex4/ex4weights.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Theta2', '__version__', '__header__', 'Theta1', '__globals__']\n",
      "(25, 401)\n",
      "(10, 26)\n",
      "(25, 400)\n",
      "(25, 1)\n",
      "(10, 25)\n",
      "(10, 1)\n"
     ]
    }
   ],
   "source": [
    "print( Theta_testvals.keys() )\n",
    "print( Theta_testvals['Theta1'].shape )\n",
    "print( Theta_testvals['Theta2'].shape )\n",
    "Theta1_testval = Theta_testvals['Theta1'][:,1:]\n",
    "b1_testval = Theta_testvals['Theta1'][:,0:1]\n",
    "print( Theta1_testval.shape )\n",
    "print( b1_testval.shape )\n",
    "Theta2_testval = Theta_testvals['Theta2'][:,1:]\n",
    "b2_testval = Theta_testvals['Theta2'][:,0:1]\n",
    "print( Theta2_testval.shape )\n",
    "print( b2_testval.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Theta1 = Layer( test_rng, 1, 400,25, 5000, activation=T.nnet.sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Theta1.Theta.set_value( Theta1_testval.astype(\"float32\"))\n",
    "Theta1.b.set_value( b1_testval.astype('float32') )\n",
    "Theta1.al.set_value( ex4data1['X'].T.astype('float32'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For $\\Theta^{(2)}$, the key to connecting $\\Theta^{(2)}$ with $\\Theta^{(1)}$ is to set the argument in class `Layer` with `al=Theta1.alp1`, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Theta2 = Layer( test_rng, 2, 25,10,5000, al=Theta1.alp1 , activation=T.nnet.sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Theta2.Theta.set_value( Theta2_testval.astype('float32'))\n",
    "Theta2.b.set_value( b2_testval.astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h_test = Theta2.alp1\n",
    "J = sandbox.cuda.basic_ops.gpu_from_host(\n",
    "    T.mean( T.sum( \n",
    "        - y_sh_var * T.log( h_test ) - ( np.float32( 1) - y_sh_var) * T.log( np.float32(1) - h_test), axis =0), axis=0)\n",
    "  )\n",
    "#J = sandbox.cuda.basic_ops.gpu_from_host( \n",
    "#    T.log(h_test) * y_sh_var\n",
    "#    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_cost_func = theano.function([],J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CudaNdarray(0.287629187107)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cost_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'theano.sandbox.cuda.var.CudaNdarraySharedVariable'>\n",
      "(10, 5000)\n",
      "<class 'theano.tensor.var.TensorVariable'>\n"
     ]
    }
   ],
   "source": [
    "print(type( y_sh_var) )\n",
    "print( y_sh_var.get_value().shape )\n",
    "print( type( h_test ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checklayer2 = theano.function([], sandbox.cuda.basic_ops.gpu_from_host(Theta1.alp1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CudaNdarray([[ 0.49435964  0.49435964  0.49435964 ...,  0.49435964  0.49435964\n",
       "   0.49435964]\n",
       " [ 0.47542453  0.47542453  0.47542453 ...,  0.47542453  0.47542453\n",
       "   0.47542453]\n",
       " [ 0.52900642  0.52900642  0.52900642 ...,  0.52900642  0.52900642\n",
       "   0.52900642]\n",
       " ..., \n",
       " [ 0.45432255  0.45432255  0.45432255 ...,  0.45432255  0.45432255\n",
       "   0.45432255]\n",
       " [ 0.33134761  0.33134761  0.33134761 ...,  0.33134761  0.33134761\n",
       "   0.33134761]\n",
       " [ 0.41315612  0.41315612  0.41315612 ...,  0.41315612  0.41315612\n",
       "   0.41315612]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checklayer2() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "testreg = theano.function([], T.sum( Theta1.Theta * Theta1.Theta ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(392.58416748046875, dtype=float32)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testreg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Thetas_lst = [ Theta1.Theta, Theta2.Theta ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sum{acc_dtype=float64}.0"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.sum( [ T.sum( theta*theta) for theta in Thetas_lst] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_func_test = cost_functional(3, 1, y_prob, Theta2.alp1, [Theta1.Theta, Theta2.Theta])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost_test = theano.function([], cost_func_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CudaNdarray(0.383769869804)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_test() # (this value should be about 0.383770)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_test = T.grad( cost_func_test,[Theta1.Theta, Theta2.Theta])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grad_test_test = theano.function([], grad_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'list'>\n",
      "2\n",
      "<type 'numpy.ndarray'>\n",
      "(25, 400)\n",
      "(10, 25)\n"
     ]
    }
   ],
   "source": [
    "print( type(grad_test_test() ) )\n",
    "print( len( grad_test_test() ))\n",
    "print( type(grad_test_test()[0] ))\n",
    "print( grad_test_test()[0].shape )\n",
    "print( grad_test_test()[1].shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5]\n",
      "['E', 'r', 'n', 'e', 's', 't']\n",
      "<type 'list'>\n"
     ]
    }
   ],
   "source": [
    "print( range(6))\n",
    "print( list( \"Ernest\") )\n",
    "zip( range(6), list(\"Ernest\"))\n",
    "print( type(grad_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Shape_i{1}(b1), Shape_i{0}(b1), GpuDimShuffle{1,0}(al), Shape_i{1}(y), Shape_i{1}(b2), Shape_i{0}(b2), GpuDimShuffle{1,0}(Theta2), GpuElemwise{mul,no_inplace}(CudaNdarrayConstant{[[  9.99999975e-05]]}, Theta2), GpuElemwise{mul,no_inplace}(CudaNdarrayConstant{[[  9.99999975e-05]]}, Theta1), GpuAlloc(b1, TensorConstant{1}, TensorConstant{5000}, Shape_i{0}.0, Shape_i{1}.0), InplaceDimShuffle{x,x}(Shape_i{1}.0), GpuAlloc(b2, TensorConstant{1}, TensorConstant{5000}, Shape_i{0}.0, Shape_i{1}.0), Elemwise{Mul}[(0, 1)](TensorConstant{5000}, Shape_i{1}.0), Elemwise{Mul}[(0, 1)](TensorConstant{5000}, Shape_i{1}.0), GpuDimShuffle{0,2,1,3}(GpuAlloc.0), Elemwise{Cast{float32}}(InplaceDimShuffle{x,x}.0), GpuDimShuffle{0,2,1,3}(GpuAlloc.0), MakeVector{dtype='int64'}(Shape_i{0}.0, Elemwise{Mul}[(0, 1)].0), MakeVector{dtype='int64'}(Shape_i{0}.0, Elemwise{Mul}[(0, 1)].0), GpuFromHost(Elemwise{Cast{float32}}.0), GpuReshape{2}(GpuDimShuffle{0,2,1,3}.0, MakeVector{dtype='int64'}.0), GpuReshape{2}(GpuDimShuffle{0,2,1,3}.0, MakeVector{dtype='int64'}.0), GpuElemwise{true_div,no_inplace}(CudaNdarrayConstant{[[-1.]]}, GpuFromHost.0), GpuGemm{inplace}(GpuReshape{2}.0, TensorConstant{1.0}, Theta1, al, TensorConstant{1.0}), GpuElemwise{ScalarSigmoid}[(0, 0)](GpuGemm{inplace}.0), GpuDimShuffle{1,0}(GpuElemwise{ScalarSigmoid}[(0, 0)].0), GpuGemm{inplace}(GpuReshape{2}.0, TensorConstant{1.0}, Theta2, GpuElemwise{ScalarSigmoid}[(0, 0)].0, TensorConstant{1.0}), GpuElemwise{Composite{(((i0 * i1 * (i2 - scalar_sigmoid(i3))) / i4) - (i5 * (i2 - i1) * scalar_sigmoid(i3)))}}[(0, 3)](CudaNdarrayConstant{[[-1.]]}, y, CudaNdarrayConstant{[[ 1.]]}, GpuGemm{inplace}.0, GpuFromHost.0, GpuElemwise{true_div,no_inplace}.0), GpuGemm{inplace}(GpuElemwise{mul,no_inplace}.0, TensorConstant{1.0}, GpuElemwise{Composite{(((i0 * i1 * (i2 - scalar_sigmoid(i3))) / i4) - (i5 * (i2 - i1) * scalar_sigmoid(i3)))}}[(0, 3)].0, GpuDimShuffle{1,0}.0, TensorConstant{2.0}), GpuDot22(GpuDimShuffle{1,0}.0, GpuElemwise{Composite{(((i0 * i1 * (i2 - scalar_sigmoid(i3))) / i4) - (i5 * (i2 - i1) * scalar_sigmoid(i3)))}}[(0, 3)].0), HostFromGpu(GpuGemm{inplace}.0), GpuElemwise{Composite{((i0 * i1) * (i2 - i1))}}[(0, 0)](GpuDot22.0, GpuElemwise{ScalarSigmoid}[(0, 0)].0, CudaNdarrayConstant{[[ 1.]]}), GpuGemm{inplace}(GpuElemwise{mul,no_inplace}.0, TensorConstant{1.0}, GpuElemwise{Composite{((i0 * i1) * (i2 - i1))}}[(0, 0)].0, GpuDimShuffle{1,0}.0, TensorConstant{2.0}), HostFromGpu(GpuGemm{inplace}.0)]\n"
     ]
    }
   ],
   "source": [
    "print( grad_test_test.maker.fgraph.toposort() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't multiply sequence by non-int of type 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-c3291a50120e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;36m0.01\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mgrad_test\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: can't multiply sequence by non-int of type 'float'"
     ]
    }
   ],
   "source": [
    "0.01 * grad_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_update = [(Theta,sandbox.cuda.basic_ops.gpu_from_host( Theta - np.float32(0.01)*T.grad(cost_func_test, Theta)+0.0001*Theta ) ) for Theta in [Theta1.Theta, Theta2.Theta] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gradDes_step = theano.function( inputs=[], updates= test_update )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_gradDes_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -1.05634514e-08   2.19436180e-09  -6.92295362e-06 ...,  -1.30543685e-05\n",
      "   -5.04227410e-06   2.80491941e-09]\n",
      " [  7.66243780e-09  -9.75969350e-09   1.04755338e-06 ...,  -5.60192129e-05\n",
      "    2.00961935e-07   3.54457574e-09]\n",
      " [ -8.77740458e-09   8.16117751e-09  -1.47759499e-06 ...,  -1.20964221e-04\n",
      "   -2.33693959e-06  -7.50741602e-09]\n",
      " ..., \n",
      " [ -8.89359164e-09  -9.82064385e-09  -7.78459707e-06 ...,   2.35335647e-05\n",
      "   -3.25518340e-06   9.02587516e-09]\n",
      " [  3.05208303e-10   2.56086108e-09  -2.11960196e-06 ...,  -8.61849287e-04\n",
      "    9.43547930e-05   3.83799614e-09]\n",
      " [  8.85963747e-09  -6.57579602e-10  -8.81727192e-06 ...,  -1.80388656e-06\n",
      "   -8.14549094e-06   8.79540707e-09]]\n",
      "[[-1.21257138 -0.10188229 -2.36874819 -1.0578922  -2.20846629  0.56389523\n",
      "   1.21117842  2.21053886  0.4446061  -1.18257177  1.04299855 -1.60575604\n",
      "   1.30433381  1.37189186  1.74843192 -0.23368138 -1.52030313  1.15336025\n",
      "   0.10369149 -0.37211585 -0.61536551 -0.12569839 -2.27216721 -0.71843761\n",
      "  -1.29703891]\n",
      " [ 0.61565566 -1.26563799  1.85764742 -0.91862833 -0.05503076 -0.38593763\n",
      "   1.2953428  -1.56859624 -0.97036505 -2.18357611 -2.85063267 -2.07754731\n",
      "   1.63180149  0.34905949  1.82808101 -2.44199824 -0.85639215 -0.29828632\n",
      "  -2.07969451 -1.2934581   0.8999148   0.28309527  2.31204581 -2.46469688\n",
      "   1.45671725]\n",
      " [-1.94558346  2.01381588 -3.12348628 -0.23620027  1.38695455  0.9099192\n",
      "  -1.54790509 -0.79839182 -0.65606695  0.73545998 -2.58620143  0.47215798\n",
      "   0.55355227  2.51281595 -2.41699743 -1.63915682  1.20285499 -1.20258307\n",
      "  -1.83465064 -1.88032556 -0.34059626  0.23694935 -1.06149018  1.02769864\n",
      "  -0.47695836]\n",
      " [ 0.46304011  0.58498383 -0.16503577  1.93284273 -0.2296816  -1.84750748\n",
      "   0.49016848  1.07157159 -3.31940198  1.54129529  0.37375814 -0.86493742\n",
      "  -2.583004    0.97072506 -0.51027173 -0.68435007 -1.64730716  0.21155307\n",
      "  -0.27425268  1.72617733  1.32432389 -2.64011979 -0.08056725 -2.03531981\n",
      "  -1.46138978]\n",
      " [-2.04503059  2.05719876  1.95121229  0.17639595 -2.16163683 -0.40398875\n",
      "   1.8017633  -1.56294954 -0.2525554   0.23588987  0.71664256  1.07700384\n",
      "  -0.3546088  -1.67760444 -0.12940609 -0.67495829  1.14078426  1.32445085\n",
      "   3.21191907 -2.15911388 -2.60191083 -3.22298121 -1.89632535 -0.87497073\n",
      "   2.51064777]\n",
      " [ 0.43445611 -0.93170726  0.18392649 -0.36082     0.61964542  0.38628966\n",
      "  -2.65177917  2.29734659 -2.08839846 -1.86401701  1.06068861  0.77570206\n",
      "   2.13490796 -1.14985681 -0.52086854  0.99753791 -1.48324752 -2.31418347\n",
      "   0.29520378 -0.38708907 -2.20630646  0.3070533  -1.17658365 -1.63479984\n",
      "  -0.82476246]\n",
      " [ 1.21576905 -1.50111604 -2.03216481 -1.52382553 -2.43757415 -2.37595034\n",
      "  -1.40001822 -0.88744533 -0.63285488  1.50465775 -1.58092761  0.58605266\n",
      "  -0.77548492  0.942671    2.10941553  0.54484761  0.43778127 -1.28037572\n",
      "  -0.0436146   1.47765326 -1.13288772 -0.72854507  0.04735166  1.65762866\n",
      "   1.68558455]\n",
      " [-0.72256583 -3.15261006  0.36581546  0.19813281 -0.73067629  1.65280986\n",
      "  -2.30059648 -1.87487686  0.98105556 -1.58841705  1.35448146  2.17917943\n",
      "  -1.99260521 -2.00392246 -0.38865316 -2.34017301 -2.91749477  0.99408847\n",
      "  -2.70504951 -1.27153015  1.86110783 -1.20531952 -0.38018176  0.70879132\n",
      "  -2.11035943]\n",
      " [ 0.53607166  1.30320907 -1.03383625 -4.03126812  0.58179194 -2.65745735\n",
      "   0.80388159 -1.09253371  2.49935699  0.36204222  0.66201895 -0.92170537\n",
      "  -0.83132339 -2.0022192  -2.94928217  0.64570653 -1.10126281  0.74517834\n",
      "   0.5851267  -1.99566114  0.62597275  1.80614579 -0.22312002 -1.40457022\n",
      "  -2.13213754]\n",
      " [-1.43959904 -1.2182219   0.71100444  0.45221624 -0.35957071  0.62291443\n",
      "  -0.67012274 -0.7069872   0.06312034 -1.2321192  -1.74663413 -2.71989202\n",
      "  -2.21460128 -1.69325113 -0.90936852  0.87861484  1.18677163 -1.87060738\n",
      "   0.39800486  1.72131801 -1.36948287  0.85815626 -0.24782105  1.2802242\n",
      "  -1.3276583 ]]\n"
     ]
    }
   ],
   "source": [
    "print( Theta1.Theta.get_value() )\n",
    "print( Theta2.Theta.get_value() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_gradDes_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -1.05644871e-08   2.19457674e-09  -6.92367394e-06 ...,  -1.30557455e-05\n",
      "   -5.04279706e-06   2.80519430e-09]\n",
      " [  7.66318919e-09  -9.76065007e-09   1.04766264e-06 ...,  -5.60250264e-05\n",
      "    2.00982896e-07   3.54492324e-09]\n",
      " [ -8.77826434e-09   8.16197776e-09  -1.47774847e-06 ...,  -1.20976787e-04\n",
      "   -2.33718265e-06  -7.50815143e-09]\n",
      " ..., \n",
      " [ -8.89446294e-09  -9.82160664e-09  -7.78540652e-06 ...,   2.35360112e-05\n",
      "   -3.25552196e-06   9.02675978e-09]\n",
      " [  3.05238224e-10   2.56111221e-09  -2.11982092e-06 ...,  -8.61938810e-04\n",
      "    9.43645937e-05   3.83837229e-09]\n",
      " [  8.86050611e-09  -6.57644050e-10  -8.81818869e-06 ...,  -1.80411416e-06\n",
      "   -8.14633404e-06   8.79626860e-09]]\n",
      "[[-1.21269774 -0.10189326 -2.36899543 -1.05800319 -2.20869637  0.56395203\n",
      "   1.21130395  2.21076775  0.44465062 -1.18269479  1.04310584 -1.60592437\n",
      "   1.30446815  1.37203324  1.74861288 -0.2337063  -1.52046156  1.15347874\n",
      "   0.10370216 -0.3721545  -0.61543089 -0.12571317 -2.27240396 -0.71851313\n",
      "  -1.29717469]\n",
      " [ 0.61571926 -1.2657696   1.85784066 -0.91872346 -0.05503564 -0.38597718\n",
      "   1.29547703 -1.56875956 -0.9704659  -2.18380332 -2.8509295  -2.07776403\n",
      "   1.63197136  0.34909612  1.82827091 -2.44225264 -0.8564809  -0.29831624\n",
      "  -2.07991028 -1.29359245  0.90000927  0.28312474  2.31228638 -2.46495295\n",
      "   1.45686901]\n",
      " [-1.9457854   2.01402569 -3.12381077 -0.23622425  1.38709962  0.91001403\n",
      "  -1.54806602 -0.79847473 -0.65613556  0.73553669 -2.58646989  0.47220758\n",
      "   0.55360955  2.51307726 -2.41724944 -1.63932729  1.20297968 -1.20270777\n",
      "  -1.83484173 -1.88052094 -0.34063154  0.23697387 -1.06160128  1.02780485\n",
      "  -0.47700837]\n",
      " [ 0.46308801  0.58504438 -0.16505313  1.93304372 -0.22970556 -1.8477\n",
      "   0.49021927  1.07168269 -3.31974745  1.54145551  0.37379676 -0.86502802\n",
      "  -2.58327293  0.97082567 -0.51032478 -0.68442118 -1.64747822  0.21157469\n",
      "  -0.27428094  1.7263571   1.32446122 -2.64039493 -0.08057581 -2.03553128\n",
      "  -1.46154177]\n",
      " [-2.04524326  2.05741334  1.95141554  0.17641492 -2.16186166 -0.40403011\n",
      "   1.80195129 -1.56311166 -0.25258079  0.23591475  0.7167182   1.07711673\n",
      "  -0.35464483 -1.67777836 -0.12941965 -0.6750282   1.14090323  1.32458937\n",
      "   3.21225333 -2.15933871 -2.60218096 -3.22331572 -1.89652169 -0.8750608\n",
      "   2.51090932]\n",
      " [ 0.43450102 -0.93180406  0.18394522 -0.36085787  0.61970943  0.3863298\n",
      "  -2.65205503  2.29758549 -2.08861589 -1.86421084  1.06079876  0.7757827\n",
      "   2.13512993 -1.14997661 -0.52092284  0.99764156 -1.48340154 -2.31442451\n",
      "   0.2952342  -0.3871294  -2.20653629  0.30708465 -1.17670619 -1.63497019\n",
      "  -0.82484829]\n",
      " [ 1.21589518 -1.5012722  -2.03237605 -1.52398372 -2.43782783 -2.37619758\n",
      "  -1.40016377 -0.88753754 -0.63292104  1.50481379 -1.58109224  0.58611315\n",
      "  -0.77556568  0.94276875  2.10963464  0.54490387  0.43782642 -1.28050911\n",
      "  -0.04361925  1.47780681 -1.13300586 -0.72862113  0.04735615  1.65780067\n",
      "   1.68575966]\n",
      " [-0.72264111 -3.1529386   0.3658531   0.19815198 -0.73075318  1.65298057\n",
      "  -2.30083585 -1.87507212  0.98115718 -1.58858275  1.35462141  2.17940545\n",
      "  -1.99281275 -2.00413132 -0.38869336 -2.34041619 -2.917799    0.99419045\n",
      "  -2.70533133 -1.27166259  1.86130106 -1.20544505 -0.38022164  0.70886451\n",
      "  -2.11057878]\n",
      " [ 0.53612489  1.30334234 -1.03394532 -4.03168917  0.58184916 -2.65773559\n",
      "   0.80396318 -1.09264815  2.49961329  0.3620764   0.66208446 -0.92180538\n",
      "  -0.83141011 -2.00242877 -2.94958925  0.64577097 -1.10137868  0.74525356\n",
      "   0.5851863  -1.99586976  0.62603438  1.80633044 -0.2231469  -1.40471911\n",
      "  -2.13235974]\n",
      " [-1.43974864 -1.21834874  0.71107888  0.4522633  -0.35960764  0.62297934\n",
      "  -0.67019254 -0.70706058  0.06312715 -1.23224759 -1.74681592 -2.72017503\n",
      "  -2.21483088 -1.69342732 -0.90946311  0.87870657  1.18689513 -1.87080216\n",
      "   0.39804676  1.7214973  -1.36962521  0.85824573 -0.24784632  1.28035724\n",
      "  -1.32779622]]\n"
     ]
    }
   ],
   "source": [
    "print( Theta1.Theta.get_value() )\n",
    "print( Theta2.Theta.get_value() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradDes_test_res = gradientDescent_step(cost_func_test, [Theta1.Theta, Theta2.Theta], 0.01, 0.00001 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "print( type(gradDes_test_res) )\n",
    "gradDes_step_test = gradDes_test_res[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradDes_step_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -1.05625011e-08   2.19416441e-09  -6.92233061e-06 ...,  -1.30531944e-05\n",
      "   -5.04182026e-06   2.80466694e-09]\n",
      " [  7.66174768e-09  -9.75881509e-09   1.04745914e-06 ...,  -5.60141707e-05\n",
      "    2.00943859e-07   3.54425689e-09]\n",
      " [ -8.77661499e-09   8.16044299e-09  -1.47746198e-06 ...,  -1.20953329e-04\n",
      "   -2.33672927e-06  -7.50674101e-09]\n",
      " ..., \n",
      " [ -8.89279139e-09  -9.81976012e-09  -7.78389676e-06 ...,   2.35314474e-05\n",
      "   -3.25489032e-06   9.02506336e-09]\n",
      " [  3.05180825e-10   2.56063060e-09  -2.11941119e-06 ...,  -8.61771696e-04\n",
      "    9.43463019e-05   3.83765109e-09]\n",
      " [  8.85883988e-09  -6.57520427e-10  -8.81647793e-06 ...,  -1.80372422e-06\n",
      "   -8.14475789e-06   8.79461570e-09]]\n",
      "[[-1.21246231 -0.10187311 -2.3685348  -1.05779707 -2.20826769  0.5638445\n",
      "   1.21106946  2.21034002  0.44456607 -1.18246531  1.04290473 -1.60561156\n",
      "   1.3042165   1.37176836  1.74827456 -0.23366036 -1.5201664   1.15325642\n",
      "   0.10368215 -0.37208235 -0.61531013 -0.12568706 -2.27196264 -0.718373\n",
      "  -1.29692221]\n",
      " [ 0.61560023 -1.26552403  1.85748029 -0.91854566 -0.05502581 -0.38590291\n",
      "   1.29522622 -1.5684551  -0.97027773 -2.18337965 -2.85037613 -2.07736039\n",
      "   1.63165462  0.34902808  1.8279165  -2.44177866 -0.85631508 -0.29825947\n",
      "  -2.07950735 -1.29334176  0.8998338   0.28306979  2.31183767 -2.46447515\n",
      "   1.45658612]\n",
      " [-1.94540834  2.01363468 -3.12320518 -0.23617902  1.38682961  0.90983731\n",
      "  -1.54776573 -0.79831994 -0.65600789  0.73539382 -2.58596873  0.47211552\n",
      "   0.55350244  2.51258993 -2.41677999 -1.63900936  1.20274675 -1.20247483\n",
      "  -1.83448553 -1.8801564  -0.34056559  0.23692803 -1.06139469  1.02760613\n",
      "  -0.47691542]\n",
      " [ 0.46299845  0.58493114 -0.16502091  1.93266881 -0.22966093 -1.84734118\n",
      "   0.49012437  1.07147515 -3.31910324  1.54115653  0.37372452 -0.86485958\n",
      "  -2.58277154  0.97063768 -0.51022583 -0.6842885  -1.64715886  0.21153402\n",
      "  -0.27422801  1.72602201  1.32420468 -2.63988233 -0.08056    -2.03513646\n",
      "  -1.46125829]\n",
      " [-2.04484653  2.05701351  1.95103669  0.17638008 -2.16144228 -0.40395239\n",
      "   1.80160105 -1.56280887 -0.25253269  0.23586865  0.71657807  1.0769068\n",
      "  -0.35457689 -1.67745352 -0.12939446 -0.67489755  1.14068162  1.32433164\n",
      "   3.21163011 -2.15891957 -2.6016767  -3.22269106 -1.89615464 -0.874892\n",
      "   2.51042175]\n",
      " [ 0.43441701 -0.93162346  0.18390995 -0.36078751  0.61958963  0.38625491\n",
      "  -2.65154052  2.29713964 -2.08821058 -1.86384928  1.06059313  0.77563226\n",
      "   2.1347158  -1.14975333 -0.52082163  0.99744815 -1.48311412 -2.3139751\n",
      "   0.29517719 -0.38705423 -2.20610809  0.30702567 -1.17647779 -1.63465273\n",
      "  -0.82468826]\n",
      " [ 1.21565962 -1.50098097 -2.03198195 -1.52368844 -2.4373548  -2.37573647\n",
      "  -1.39989233 -0.88736546 -0.6327979   1.50452232 -1.58078539  0.58599991\n",
      "  -0.77541512  0.94258612  2.10922575  0.54479861  0.43774188 -1.28026056\n",
      "  -0.04361067  1.47752023 -1.1327858  -0.7284795   0.0473474   1.65747941\n",
      "   1.68543291]\n",
      " [-0.7225008  -3.15232635  0.36578253  0.19811498 -0.73061055  1.65266109\n",
      "  -2.30038953 -1.87470806  0.98096728 -1.588274    1.35435963  2.17898345\n",
      "  -1.9924258  -2.00374198 -0.3886182  -2.33996224 -2.91723228  0.993999\n",
      "  -2.70480609 -1.27141571  1.86094034 -1.20521104 -0.38014755  0.70872754\n",
      "  -2.11016965]\n",
      " [ 0.53602344  1.30309176 -1.03374326 -4.03090572  0.5817396  -2.65721822\n",
      "   0.80380923 -1.09243536  2.49913216  0.36200964  0.66195935 -0.92162246\n",
      "  -0.83124858 -2.00203896 -2.94901681  0.64564842 -1.10116363  0.74511129\n",
      "   0.58507401 -1.99548161  0.62591642  1.8059833  -0.22309995 -1.40444386\n",
      "  -2.13194585]\n",
      " [-1.43946946 -1.21811223  0.71094042  0.45217556 -0.35953835  0.62285841\n",
      "  -0.67006248 -0.7069236   0.06311466 -1.23200822 -1.74647701 -2.71964717\n",
      "  -2.21440196 -1.69309878 -0.90928668  0.87853581  1.18666482 -1.87043905\n",
      "   0.39796904  1.72116315 -1.36935961  0.85807902 -0.24779876  1.28010905\n",
      "  -1.32753885]]\n"
     ]
    }
   ],
   "source": [
    "print( Theta1.Theta.get_value() )\n",
    "print( Theta2.Theta.get_value() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradDes_step_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -1.05625855e-08   2.19418195e-09  -6.92242747e-06 ...,  -1.30533963e-05\n",
      "   -5.04188938e-06   2.80468937e-09]\n",
      " [  7.66180897e-09  -9.75889325e-09   1.04747403e-06 ...,  -5.60149419e-05\n",
      "    2.00946744e-07   3.54428531e-09]\n",
      " [ -8.77668516e-09   8.16050871e-09  -1.47748244e-06 ...,  -1.20955003e-04\n",
      "   -2.33676201e-06  -7.50680140e-09]\n",
      " ..., \n",
      " [ -8.89286245e-09  -9.81983916e-09  -7.78400590e-06 ...,   2.35317766e-05\n",
      "   -3.25493579e-06   9.02513619e-09]\n",
      " [  3.05183268e-10   2.56065102e-09  -2.11943939e-06 ...,  -8.61783628e-04\n",
      "    9.43476116e-05   3.83768217e-09]\n",
      " [  8.85891094e-09  -6.57525701e-10  -8.81660071e-06 ...,  -1.80378925e-06\n",
      "   -8.14486793e-06   8.79468587e-09]]\n",
      "[[-1.21247959 -0.10187493 -2.36856866 -1.05781281 -2.20829916  0.56385064\n",
      "   1.21108603  2.21037006  0.44457057 -1.18248188  1.04291832 -1.6056354\n",
      "   1.30423355  1.37178624  1.74829817 -0.23366424 -1.52018797  1.15327108\n",
      "   0.10368349 -0.37208751 -0.61532009 -0.12569052 -2.27199483 -0.71838391\n",
      "  -1.29694128]\n",
      " [ 0.61560839 -1.26554167  1.85750628 -0.91855812 -0.05502573 -0.38590774\n",
      "   1.29524386 -1.56847727 -0.97029126 -2.18341041 -2.85041642 -2.07738996\n",
      "   1.63167763  0.34903327  1.82794189 -2.44181347 -0.85632676 -0.29826254\n",
      "  -2.07953596 -1.29335976  0.89984727  0.28307381  2.3118701  -2.46450949\n",
      "   1.45660675]\n",
      " [-1.94543517  2.01366329 -3.12324858 -0.23618175  1.38684976  0.9098503\n",
      "  -1.54778731 -0.7983309  -0.65601742  0.73540437 -2.5860045   0.47212264\n",
      "   0.55350989  2.51262522 -2.41681457 -1.63903248  1.20276332 -1.20249116\n",
      "  -1.83451152 -1.8801825  -0.34057021  0.23693123 -1.06141019  1.02761996\n",
      "  -0.47692251]\n",
      " [ 0.46300465  0.58493906 -0.16502343  1.93269575 -0.22966421 -1.84736741\n",
      "   0.49013108  1.07148981 -3.31914997  1.54117799  0.37372953 -0.86487234\n",
      "  -2.58280778  0.97065091 -0.51023299 -0.68429804 -1.64718163  0.2115366\n",
      "  -0.27423158  1.72604644  1.3242228  -2.63991976 -0.0805613  -2.03516483\n",
      "  -1.4612788 ]\n",
      " [-2.04487514  2.05704284  1.95106435  0.17638318 -2.16147256 -0.4039574\n",
      "   1.8016268  -1.56283033 -0.25253534  0.23587231  0.71658915  1.07692266\n",
      "  -0.354581   -1.67747641 -0.12939636 -0.67490661  1.14069796  1.32435095\n",
      "   3.21167541 -2.15895009 -2.60171247 -3.2227354  -1.89618027 -0.87490332\n",
      "   2.51045728]\n",
      " [ 0.43442282 -0.93163645  0.18391213 -0.36079288  0.61959785  0.38626033\n",
      "  -2.65157771  2.29717159 -2.08824015 -1.86387539  1.06060791  0.77564305\n",
      "   2.1347456  -1.14976966 -0.52082902  0.99746203 -1.48313475 -2.31400776\n",
      "   0.29518107 -0.38705969 -2.20613933  0.30702943 -1.17649448 -1.63467586\n",
      "  -0.82469988]\n",
      " [ 1.21567631 -1.50100219 -2.03201032 -1.52370954 -2.4373889  -2.37576985\n",
      "  -1.39991188 -0.8873778  -0.63280708  1.50454307 -1.58080781  0.58600765\n",
      "  -0.77542609  0.94259894  2.10925508  0.54480588  0.43774763 -1.2802788\n",
      "  -0.0436114   1.47754073 -1.13280201 -0.72849     0.04734763  1.65750217\n",
      "   1.6854564 ]\n",
      " [-0.72251105 -3.15237093  0.36578727  0.19811635 -0.73062164  1.65268302\n",
      "  -2.30042195 -1.87473452  0.98098069 -1.58829641  1.35437787  2.17901349\n",
      "  -1.99245393 -2.00377035 -0.38862342 -2.33999467 -2.917274    0.99401158\n",
      "  -2.70484447 -1.27143371  1.86096621 -1.20522809 -0.38015315  0.70873696\n",
      "  -2.11019921]\n",
      " [ 0.53602844  1.30310774 -1.03375936 -4.0309639   0.58174449 -2.65725732\n",
      "   0.80381852 -1.09245145  2.49916363  0.36201128  0.66196531 -0.92163956\n",
      "  -0.8312605  -2.00206828 -2.94905853  0.6456548  -1.10118032  0.74511951\n",
      "   0.58508086 -1.9955107   0.62592179  1.8060056  -0.22310673 -1.40446639\n",
      "  -2.13197637]\n",
      " [-1.43948936 -1.2181294   0.71095073  0.45218194 -0.35954288  0.62286729\n",
      "  -0.67007202 -0.70693338  0.06311581 -1.23202562 -1.74650168 -2.71968532\n",
      "  -2.21443224 -1.69312251 -0.90929943  0.8785485   1.18668139 -1.87046552\n",
      "   0.39797512  1.72118759 -1.36937869  0.85809124 -0.24780172  1.28012693\n",
      "  -1.32755733]]\n"
     ]
    }
   ],
   "source": [
    "print( Theta1.Theta.get_value() )\n",
    "print( Theta2.Theta.get_value() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 5000)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex4data1['y'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.872569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "count  5000.000000\n",
       "mean      5.500000\n",
       "std       2.872569\n",
       "min       1.000000\n",
       "25%       3.000000\n",
       "50%       5.500000\n",
       "75%       8.000000\n",
       "max      10.000000"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame( ex4data1['y']).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape.0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print( Theta2.alp1.shape )\n",
    "print( Theta2.alp1.shape.ndim )\n",
    "# Theta2.alp1.shape.get_scalar_constant_value()\n",
    "predicted_logreg = theano.function([],Theta2.alp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5.000000e+03</td>\n",
       "      <td>5.000000e+03</td>\n",
       "      <td>5.000000e+03</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5.000000e+03</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.100628</td>\n",
       "      <td>1.003652e-01</td>\n",
       "      <td>1.003967e-01</td>\n",
       "      <td>1.004417e-01</td>\n",
       "      <td>0.100253</td>\n",
       "      <td>1.005637e-01</td>\n",
       "      <td>0.100360</td>\n",
       "      <td>0.100543</td>\n",
       "      <td>0.100846</td>\n",
       "      <td>0.100248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.280952</td>\n",
       "      <td>2.710659e-01</td>\n",
       "      <td>2.669757e-01</td>\n",
       "      <td>2.724109e-01</td>\n",
       "      <td>0.267206</td>\n",
       "      <td>2.798822e-01</td>\n",
       "      <td>0.275913</td>\n",
       "      <td>0.264708</td>\n",
       "      <td>0.264970</td>\n",
       "      <td>0.284639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000010</td>\n",
       "      <td>4.299332e-07</td>\n",
       "      <td>9.454787e-07</td>\n",
       "      <td>2.587024e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>7.190226e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000301</td>\n",
       "      <td>8.055457e-04</td>\n",
       "      <td>7.226729e-04</td>\n",
       "      <td>1.883787e-04</td>\n",
       "      <td>0.000919</td>\n",
       "      <td>2.311849e-04</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>0.001162</td>\n",
       "      <td>0.000871</td>\n",
       "      <td>0.000253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.001198</td>\n",
       "      <td>4.066701e-03</td>\n",
       "      <td>4.143638e-03</td>\n",
       "      <td>1.152211e-03</td>\n",
       "      <td>0.003805</td>\n",
       "      <td>1.742870e-03</td>\n",
       "      <td>0.002029</td>\n",
       "      <td>0.004935</td>\n",
       "      <td>0.004056</td>\n",
       "      <td>0.001377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.006197</td>\n",
       "      <td>1.748446e-02</td>\n",
       "      <td>1.921718e-02</td>\n",
       "      <td>1.193071e-02</td>\n",
       "      <td>0.017761</td>\n",
       "      <td>9.229897e-03</td>\n",
       "      <td>0.011941</td>\n",
       "      <td>0.020477</td>\n",
       "      <td>0.018032</td>\n",
       "      <td>0.006297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.993053</td>\n",
       "      <td>9.996013e-01</td>\n",
       "      <td>9.982013e-01</td>\n",
       "      <td>9.986625e-01</td>\n",
       "      <td>0.999188</td>\n",
       "      <td>9.985297e-01</td>\n",
       "      <td>0.999378</td>\n",
       "      <td>0.998737</td>\n",
       "      <td>0.996482</td>\n",
       "      <td>0.998724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0             1             2             3            4  \\\n",
       "count  5000.000000  5.000000e+03  5.000000e+03  5.000000e+03  5000.000000   \n",
       "mean      0.100628  1.003652e-01  1.003967e-01  1.004417e-01     0.100253   \n",
       "std       0.280952  2.710659e-01  2.669757e-01  2.724109e-01     0.267206   \n",
       "min       0.000010  4.299332e-07  9.454787e-07  2.587024e-07     0.000002   \n",
       "25%       0.000301  8.055457e-04  7.226729e-04  1.883787e-04     0.000919   \n",
       "50%       0.001198  4.066701e-03  4.143638e-03  1.152211e-03     0.003805   \n",
       "75%       0.006197  1.748446e-02  1.921718e-02  1.193071e-02     0.017761   \n",
       "max       0.993053  9.996013e-01  9.982013e-01  9.986625e-01     0.999188   \n",
       "\n",
       "                  5            6            7            8            9  \n",
       "count  5.000000e+03  5000.000000  5000.000000  5000.000000  5000.000000  \n",
       "mean   1.005637e-01     0.100360     0.100543     0.100846     0.100248  \n",
       "std    2.798822e-01     0.275913     0.264708     0.264970     0.284639  \n",
       "min    7.190226e-07     0.000002     0.000003     0.000008     0.000001  \n",
       "25%    2.311849e-04     0.000240     0.001162     0.000871     0.000253  \n",
       "50%    1.742870e-03     0.002029     0.004935     0.004056     0.001377  \n",
       "75%    9.229897e-03     0.011941     0.020477     0.018032     0.006297  \n",
       "max    9.985297e-01     0.999378     0.998737     0.996482     0.998724  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame( predicted_logreg().T ).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fc5ee56a110>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAD8CAYAAACYebj1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBwUzMys5KJiZWclBwczMSg4KZmZW+g0fjtATMzV4IAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc5ee3911d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(predicted_logreg().T).describe().iloc[1:-1,:].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5000, 1)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print( np.argmax( predicted_logreg(), axis=0).shape )\n",
    "np.vstack( np.argmax( predicted_logreg(),axis=0) ).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.504000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.874933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "count  5000.000000\n",
       "mean      5.504000\n",
       "std       2.874933\n",
       "min       1.000000\n",
       "25%       3.000000\n",
       "50%       6.000000\n",
       "75%       8.000000\n",
       "max      10.000000"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame( np.vstack( np.argmax(predicted_logreg(),axis=0)) + 1).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.975200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.155534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "count  5000.000000\n",
       "mean      0.975200\n",
       "std       0.155534\n",
       "min       0.000000\n",
       "25%       1.000000\n",
       "50%       1.000000\n",
       "75%       1.000000\n",
       "max       1.000000"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = np.float32( ( np.vstack( np.argmax( predicted_logreg(),axis=0)) + 1 ) == ex4data1['y'] )\n",
    "pd.DataFrame(res).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 5000)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_logreg().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 5000)\n",
      "(5000,)\n"
     ]
    }
   ],
   "source": [
    "print(y_prob.shape); print( np.argmax( y_prob,axis=0 ).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Summary for Neural Net with Multiple Layers for logistic regression (but can be extended to linear regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *Load boilerplate training data:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append( os.getcwd() + '/ML' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NN import Layer, cost_functional, cost_functional_noreg, gradientDescent_step, MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and Visualizing Data ... \n",
      "\n",
      "(400, 5000)\n",
      "(10, 5000)\n"
     ]
    }
   ],
   "source": [
    "# Load Training Data\n",
    "print(\"Loading and Visualizing Data ... \\n\")\n",
    "ex4data1 = scipy.io.loadmat('./coursera_Ng/machine-learning-ex4/ex4/ex4data1.mat')\n",
    "\n",
    "# recall that whereas the original labels (in the variable y) were 1, 2, ..., 10, for the purpose of training a \n",
    "# neural network, we need to recode the labels as vectors containing only values 0 or 1\n",
    "K=10\n",
    "m = ex4data1['y'].shape[0]\n",
    "y_prob = [np.zeros(K) for row in ex4data1['y']]  # list of 5000 numpy arrays of size dims. (10,)\n",
    "for i in range( m):\n",
    "        y_prob[i][ ex4data1['y'][i]-1] = 1\n",
    "y_prob = np.array(y_prob).T.astype(theano.config.floatX)  # size dims. (K,m)\n",
    "\n",
    "print(ex4data1['X'].T.shape)\n",
    "print(y_prob.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "digitsMLP = MLP(3,[400,25,10], 5000, ex4data1['X'].T, y_prob, T.nnet.sigmoid, 1., 0.1, 0.0000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "digitsMLP.train_model(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score : 0.991200 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.99119999999999997"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digitsMLP.accuracy_log_reg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.03968292  0.01570808 -0.00801071 ...,  0.05324144 -0.03536524\n",
      "  -0.02519361]\n",
      " [ 0.02765682  0.02882705 -0.06191737 ..., -0.01663327  0.03339296\n",
      "  -0.02493248]\n",
      " [ 0.01494016 -0.03611031  0.04792143 ...,  0.0510212  -0.00466521\n",
      "  -0.00434607]\n",
      " ..., \n",
      " [ 0.03901267 -0.03169481  0.06044593 ..., -0.0364962  -0.03772442\n",
      "   0.01351396]\n",
      " [ 0.03186403  0.05424397  0.02720479 ...,  0.01087107 -0.01080637\n",
      "   0.01786175]\n",
      " [ 0.06252811 -0.04008792  0.06331227 ..., -0.04469054  0.02635518\n",
      "   0.04384876]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.20451474,  0.83254075,  0.3577919 ,  2.09141254,  0.30367732,\n",
       "         1.70919907, -0.68671805,  1.94035482,  0.6540705 , -2.20026374,\n",
       "         1.0235399 , -1.10299885,  0.87818861,  2.8505857 , -2.22271323,\n",
       "        -2.00406885, -2.60233808, -0.85654968, -2.76958466, -1.48524833,\n",
       "        -3.17246437, -0.06278938,  0.616503  ,  3.52648425,  0.98629874],\n",
       "       [ 2.60660052, -0.10535918,  1.22893441,  2.44127226, -3.89616203,\n",
       "        -3.1201973 , -2.51445174,  1.34601641,  3.96324277, -2.53724122,\n",
       "        -3.20322871,  0.95207882, -2.91599441, -2.66748142,  1.32648623,\n",
       "         0.81661856,  1.32140303, -0.87079829, -0.53782797, -1.90582633,\n",
       "         3.33778262, -0.50736022, -0.66713619, -1.36594701,  2.1127429 ],\n",
       "       [-1.43893147,  1.59595168,  0.58790714,  3.8221848 ,  4.65350819,\n",
       "        -2.22888541, -1.92654026, -1.48021591, -3.24884081, -2.0549016 ,\n",
       "         2.35445762,  3.15103745, -1.86801529,  2.50599551, -0.51754326,\n",
       "        -0.61664522, -1.13638568, -3.49592352, -0.14462674,  0.52218926,\n",
       "         0.94804603,  0.48102653, -2.2381053 , -2.80585504, -2.67067432],\n",
       "       [-0.97880727, -3.42777109, -3.0412941 ,  0.07771082,  0.56903011,\n",
       "        -0.83924389,  1.42225981,  2.75040054, -1.39653993,  1.39573848,\n",
       "         1.54833257, -2.28482318, -1.19908345, -1.23934305,  0.1012596 ,\n",
       "         0.41159233, -4.30142689, -1.29635179,  2.10533142, -0.36743957,\n",
       "         1.919065  , -5.38604879, -0.68395364,  1.60128868, -0.92604429],\n",
       "       [-2.21723104,  0.94654542,  2.71510959, -3.15821409,  1.2421279 ,\n",
       "         1.54322195,  2.38756323, -0.35632336,  1.59020221, -2.20207787,\n",
       "        -2.31908298, -0.23842566,  2.842659  , -1.16831934, -1.10033369,\n",
       "         2.3584559 , -2.86785245,  2.43999338,  2.25221205, -2.86637926,\n",
       "        -3.29994965,  0.2062892 , -2.27796054, -1.90024221,  5.06210709],\n",
       "       [-0.41967511,  2.81876731, -3.19176626, -2.13696814, -1.76408064,\n",
       "         1.12407899,  3.01087523,  2.11157274, -1.18705463,  1.32382548,\n",
       "        -0.06723422,  0.01781415,  2.63719058, -2.33022046, -1.4483918 ,\n",
       "        -2.91259265,  1.15207839, -1.17236662, -2.97872806, -0.56889361,\n",
       "        -1.30872059, -1.56629968,  1.08266664, -1.98741114, -0.89212441],\n",
       "       [-0.6513139 , -0.67716223, -3.03075981,  2.60289288, -2.83682179,\n",
       "        -1.9186002 , -2.81462193, -1.34299827, -2.06861496, -2.43334413,\n",
       "         2.26945639, -0.2679739 , -0.33434728, -1.78550529, -0.60505742,\n",
       "         1.65669274,  0.72454143,  2.54930949,  1.80095565, -0.6691587 ,\n",
       "        -2.79404688,  0.49601215,  3.74682832,  1.82545471,  0.06220638],\n",
       "       [-0.31317323, -2.17267513,  3.26154256, -0.96487314, -3.19127011,\n",
       "         4.00027752,  1.55789506, -3.2021575 , -3.13566351,  2.24683571,\n",
       "        -1.71402073, -1.77391756, -3.39949989,  1.01905394, -0.05652857,\n",
       "         1.37401104, -0.78254008, -2.96524358, -2.75739622, -1.48058116,\n",
       "        -1.42676282, -1.46033561,  2.61433244, -2.85393929, -3.30281448],\n",
       "       [ 2.51441741, -2.35930371, -2.45756555, -2.2026875 ,  3.0209465 ,\n",
       "         1.47433209,  1.19607747, -2.47334051, -0.01969391,  3.09615278,\n",
       "        -2.00905395,  0.31061357, -2.11481953, -1.13638878, -2.71792459,\n",
       "        -1.84998   ,  2.16689348, -3.52886462,  0.64545244, -2.02436543,\n",
       "        -0.21113941,  4.98415565, -3.85935426,  1.63133836, -1.07641482],\n",
       "       [-1.74175525, -2.37122393,  1.55441034,  0.23550114, -1.96717358,\n",
       "        -1.83210754, -3.25745535, -1.22520483, -0.62219352,  2.43008757,\n",
       "        -0.22606266, -0.01252492,  1.41700852,  0.24551152, -0.73388177,\n",
       "        -3.98788357,  1.05824101,  3.25433969,  0.86931092, -0.00776808,\n",
       "         0.05484827, -0.38054886,  0.17874011, -1.70390856, -0.95664531]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print( digitsMLP.Thetas[0].Theta.get_value() )\n",
    "digitsMLP.Thetas[1].Theta.get_value()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.69714658e-05,   6.81859674e-05,   4.40727854e-06, ...,\n",
       "          5.32231061e-03,   2.53793423e-05,   1.24584597e-06],\n",
       "       [  1.01746270e-03,   4.22267512e-05,   4.14312631e-03, ...,\n",
       "          2.78708263e-04,   5.46442550e-07,   2.42858031e-03],\n",
       "       [  1.28256984e-03,   2.17894791e-03,   8.93946737e-04, ...,\n",
       "          7.34846219e-02,   1.61182688e-04,   1.05979457e-03],\n",
       "       ..., \n",
       "       [  5.44993207e-04,   4.99824178e-04,   2.40481794e-02, ...,\n",
       "          1.57466289e-04,   6.36213226e-03,   3.31715518e-03],\n",
       "       [  8.89896415e-04,   6.08195027e-04,   1.27942930e-03, ...,\n",
       "          8.00565720e-01,   9.88285422e-01,   7.53709316e-01],\n",
       "       [  9.96679068e-01,   9.98024583e-01,   9.72293377e-01, ...,\n",
       "          6.17099488e-07,   1.53781421e-05,   1.62253886e-01]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digitsMLP.predicted_vals_logreg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.68952462e-03   9.66312247e-04   3.05149867e-03 ...,   6.01312637e-01\n",
      "    7.69796073e-02   1.04411095e-02]\n",
      " [  5.63030466e-02   3.84460762e-02   3.80754247e-02 ...,   5.98353744e-01\n",
      "    2.61052395e-04   2.27537050e-04]\n",
      " [  9.90030646e-01   9.98632133e-01   9.82155979e-01 ...,   1.93933040e-01\n",
      "    4.72371355e-02   2.82941740e-02]\n",
      " ..., \n",
      " [  3.31877563e-05   3.73444600e-05   8.24407116e-03 ...,   2.87410337e-03\n",
      "    5.70651256e-02   5.32165647e-01]\n",
      " [  3.52760107e-04   9.42657294e-04   9.13141354e-04 ...,   6.50500178e-01\n",
      "    9.91682410e-01   3.51258606e-01]\n",
      " [  5.73539697e-02   9.71803325e-04   3.29945865e-03 ...,   6.90432638e-02\n",
      "    1.61013941e-05   1.03116455e-03]]\n",
      "[[  1.68952462e-03   9.66312247e-04   3.05149867e-03 ...,   6.01312637e-01\n",
      "    7.69796073e-02   1.04411095e-02]\n",
      " [  5.63030466e-02   3.84460762e-02   3.80754247e-02 ...,   5.98353744e-01\n",
      "    2.61052395e-04   2.27537050e-04]\n",
      " [  9.90030646e-01   9.98632133e-01   9.82155979e-01 ...,   1.93933040e-01\n",
      "    4.72371355e-02   2.82941740e-02]\n",
      " ..., \n",
      " [  3.31877563e-05   3.73444600e-05   8.24407116e-03 ...,   2.87410337e-03\n",
      "    5.70651256e-02   5.32165647e-01]\n",
      " [  3.52760107e-04   9.42657294e-04   9.13141354e-04 ...,   6.50500178e-01\n",
      "    9.91682410e-01   3.51258606e-01]\n",
      " [  5.73539697e-02   9.71803325e-04   3.29945865e-03 ...,   6.90432638e-02\n",
      "    1.61013941e-05   1.03116455e-03]]\n"
     ]
    }
   ],
   "source": [
    "testL1a2 = theano.function([], digitsMLP.Thetas[0].alp1 )\n",
    "print( testL1a2() )\n",
    "testL2a2 = theano.function([], digitsMLP.Thetas[1].al )\n",
    "print( testL2a2() )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 8, 1, 5]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1,2,3,4,5] + [8,1,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 5000)\n",
      "(5000, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.872569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "count  5000.000000\n",
       "mean      4.500000\n",
       "std       2.872569\n",
       "min       0.000000\n",
       "25%       2.000000\n",
       "50%       4.500000\n",
       "75%       7.000000\n",
       "max       9.000000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print( digitsMLP.y.shape )\n",
    "y_cls_test = np.vstack( np.argmax( digitsMLP.y, axis=0) )\n",
    "print( y_cls_test.shape )\n",
    "pd.DataFrame( y_cls_test ).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.499000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.879315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "count  5000.000000\n",
       "mean      4.499000\n",
       "std       2.879315\n",
       "min       0.000000\n",
       "25%       2.000000\n",
       "50%       5.000000\n",
       "75%       7.000000\n",
       "max       9.000000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_y_cls_test = np.vstack( np.argmax( digitsMLP.predicted_vals_logreg() , axis=0))\n",
    "print( pred_y_cls_test.shape )\n",
    "pd.DataFrame( pred_y_cls_test ).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99119999999999997"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean( pred_y_cls_test == y_cls_test )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Testing on MNIST, from University of Montreal, Deep Learning Tutorial, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 50000)\n"
     ]
    }
   ],
   "source": [
    "K=10\n",
    "m = len(train_set[1])\n",
    "y_train_prob = [np.zeros(K) for row in train_set[1]]  # list of 5000 numpy arrays of size dims. (10,)\n",
    "for i in range( m):\n",
    "        y_train_prob[i][ train_set[1][i]] = 1\n",
    "y_train_prob = np.array(y_train_prob).T.astype(theano.config.floatX)  # size dims. (K,m)\n",
    "print( y_train_prob.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0          1          2          3          4          5      \\\n",
      "count  10.000000  10.000000  10.000000  10.000000  10.000000  10.000000   \n",
      "mean    0.100000   0.100000   0.100000   0.100000   0.100000   0.100000   \n",
      "std     0.316228   0.316228   0.316228   0.316228   0.316228   0.316228   \n",
      "min     0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
      "25%     0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
      "50%     0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
      "75%     0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
      "max     1.000000   1.000000   1.000000   1.000000   1.000000   1.000000   \n",
      "\n",
      "           6          7          8          9        ...          49990  \\\n",
      "count  10.000000  10.000000  10.000000  10.000000    ...      10.000000   \n",
      "mean    0.100000   0.100000   0.100000   0.100000    ...       0.100000   \n",
      "std     0.316228   0.316228   0.316228   0.316228    ...       0.316228   \n",
      "min     0.000000   0.000000   0.000000   0.000000    ...       0.000000   \n",
      "25%     0.000000   0.000000   0.000000   0.000000    ...       0.000000   \n",
      "50%     0.000000   0.000000   0.000000   0.000000    ...       0.000000   \n",
      "75%     0.000000   0.000000   0.000000   0.000000    ...       0.000000   \n",
      "max     1.000000   1.000000   1.000000   1.000000    ...       1.000000   \n",
      "\n",
      "           49991      49992      49993      49994      49995      49996  \\\n",
      "count  10.000000  10.000000  10.000000  10.000000  10.000000  10.000000   \n",
      "mean    0.100000   0.100000   0.100000   0.100000   0.100000   0.100000   \n",
      "std     0.316228   0.316228   0.316228   0.316228   0.316228   0.316228   \n",
      "min     0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
      "25%     0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
      "50%     0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
      "75%     0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
      "max     1.000000   1.000000   1.000000   1.000000   1.000000   1.000000   \n",
      "\n",
      "           49997      49998      49999  \n",
      "count  10.000000  10.000000  10.000000  \n",
      "mean    0.100000   0.100000   0.100000  \n",
      "std     0.316228   0.316228   0.316228  \n",
      "min     0.000000   0.000000   0.000000  \n",
      "25%     0.000000   0.000000   0.000000  \n",
      "50%     0.000000   0.000000   0.000000  \n",
      "75%     0.000000   0.000000   0.000000  \n",
      "max     1.000000   1.000000   1.000000  \n",
      "\n",
      "[8 rows x 50000 columns]\n"
     ]
    }
   ],
   "source": [
    "print( pd.DataFrame( y_train_prob).describe() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m,d= train_set[0].shape\n",
    "MNIST_MTL = MLP(3,[d,25,10], m, train_set[0].T, y_train_prob, T.nnet.sigmoid, 1., 0.1, 0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score : 0.095720 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.09572"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MNIST_MTL.accuracy_log_reg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.21252947  0.08412755 -0.04290283 ...,  0.07965862 -0.23788518\n",
      "   0.22836781]\n",
      " [ 0.21750133 -0.28106511  0.2671701  ...,  0.05657074 -0.29780233\n",
      "  -0.34037825]\n",
      " [-0.02203849  0.19995408  0.29139307 ..., -0.0802632   0.14923781\n",
      "  -0.01326215]\n",
      " ..., \n",
      " [-0.09192752  0.2681919   0.26859927 ...,  0.06894684  0.12018485\n",
      "  -0.32358104]\n",
      " [-0.13953739  0.02424429 -0.20282558 ...,  0.13586117 -0.29190949\n",
      "   0.01420764]\n",
      " [ 0.14536618 -0.06120829 -0.19793963 ...,  0.02141157 -0.26165357\n",
      "  -0.22347094]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.39743981,  0.47411704, -0.06570012, -1.42164946, -1.16744244,\n",
       "        -0.44029245,  1.55344975,  0.42985651,  0.42142299,  0.34747389,\n",
       "        -0.81492281, -1.56219399,  0.82000202, -0.40216985,  1.47232902,\n",
       "         0.35999769,  0.68932515,  0.82125103, -0.06185548, -0.27060255,\n",
       "        -0.25692338, -0.86920112, -1.25981688,  1.49232507,  0.52447045],\n",
       "       [-0.45812011, -1.22509992, -1.14734924,  0.8219015 ,  0.67774659,\n",
       "        -0.54277843, -0.51398909, -1.19371367,  1.41380441,  0.30840605,\n",
       "        -0.11502755,  0.03701442, -0.82230645,  0.57699567,  1.3465414 ,\n",
       "         0.46789521,  0.72777843, -0.74098152,  1.17320132,  0.3995336 ,\n",
       "         0.79102081, -0.1648806 , -0.07733183, -1.60657287, -0.64839828],\n",
       "       [-0.26341805,  1.1494323 , -0.1576034 , -0.51010013, -1.4537679 ,\n",
       "        -0.32284725, -0.11438043, -0.16837011, -0.92213452, -1.61426508,\n",
       "        -1.34188533, -0.43147799, -0.61895543,  1.38522243, -0.58895016,\n",
       "        -0.7618435 ,  0.89010906, -0.43544725,  0.9864412 ,  1.43864715,\n",
       "        -1.04564011,  1.22792351,  1.51681113,  1.48080194,  0.77915668],\n",
       "       [ 0.20965257,  0.96099746, -1.38709569, -0.71545523,  1.10635912,\n",
       "        -1.29045534, -1.57748663, -0.95929617, -0.24077024, -0.35265234,\n",
       "        -0.75665629, -1.07101023, -0.00545067, -0.99316341,  1.4602592 ,\n",
       "         0.7212196 , -0.10515147,  0.49578574,  1.45931995,  1.07267094,\n",
       "        -0.01084974,  1.01463413, -0.73990732, -0.75446784, -1.58813906],\n",
       "       [ 1.26138949, -0.47427896, -0.4497835 , -0.19745249, -0.21095291,\n",
       "        -0.08235157,  1.11536026,  0.04610212,  1.11256003, -0.46868172,\n",
       "         0.98976576,  0.5969364 ,  1.2798928 , -0.48845506, -1.03150034,\n",
       "         0.96056491,  0.30198944,  1.47925031,  0.36784145,  0.33264968,\n",
       "         0.26245806,  0.48660216,  0.96751767, -1.27767527,  0.42533398],\n",
       "       [-1.35573721, -0.85225189,  0.39260316,  1.22144449, -0.31289348,\n",
       "        -0.9116798 , -1.23236263,  0.81047082,  0.68190771,  0.23868939,\n",
       "         0.48585162,  0.1120138 , -0.15501086,  0.46083274,  1.03472054,\n",
       "         1.32915258, -1.44029725, -0.71790475,  1.60148978,  0.20379403,\n",
       "         1.15068221, -1.49505317, -0.42173779, -0.72793669,  0.96851325],\n",
       "       [ 1.43791103, -0.69099313, -0.79151177,  0.21312031,  1.36474013,\n",
       "        -1.19343758, -0.45168665,  0.60482723,  0.41439977, -1.3197763 ,\n",
       "        -1.09207129,  0.23710582,  0.06775524, -0.72686183,  0.96668959,\n",
       "         0.09902351,  0.4042387 , -0.44409871, -0.26330748,  1.35316038,\n",
       "        -1.48465347,  1.03650403,  0.71476686,  1.63380992,  0.13157721],\n",
       "       [-0.90288603,  1.17905378,  1.22328877,  1.41004956,  0.29629964,\n",
       "        -0.9095031 , -0.23757875,  1.6151613 , -1.52695167, -1.07278395,\n",
       "         1.56079459,  0.52057123, -1.35828531, -1.01550984,  0.75505394,\n",
       "        -0.20916736, -0.56811482, -0.02100989,  1.45307636, -1.61759782,\n",
       "        -0.51052654, -1.48488081,  1.15462708, -1.02267063, -1.04683352],\n",
       "       [ 1.52449572,  1.1317147 ,  0.56625313,  1.33766675, -0.3755441 ,\n",
       "         0.9018296 ,  0.18880704, -0.07619639, -0.89904916,  1.51346755,\n",
       "        -0.34904653, -0.45106241,  1.63571787,  0.12569541,  1.17675114,\n",
       "        -0.60786849, -0.92819321,  0.43607047,  1.23182929, -0.37070179,\n",
       "         0.63889045, -1.0101124 , -1.28258407,  1.46705651, -0.69088858],\n",
       "       [-1.50364363,  1.22934222,  0.83844817,  0.65174961, -1.37190723,\n",
       "        -0.32444778, -0.26416573,  0.29394153, -0.66541278,  0.23971787,\n",
       "         0.32632565, -1.46561682, -0.02179751, -1.46791589, -0.15427259,\n",
       "        -0.18021606, -0.39853364, -0.67619216, -0.01778612, -0.78865045,\n",
       "        -1.53309178,  0.3225404 ,  1.01434851,  0.08351628,  1.15306926]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print( MNIST_MTL.Thetas[0].Theta.get_value() )\n",
    "MNIST_MTL.Thetas[1].Theta.get_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.77596611,  0.75060475,  0.423906  , ...,  0.60422331,\n",
       "         0.40988356,  0.31822193],\n",
       "       [ 0.34422615,  0.67563272,  0.273395  , ...,  0.20291083,\n",
       "         0.3232716 ,  0.4690749 ],\n",
       "       [ 0.93080932,  0.28231877,  0.59183002, ...,  0.95939362,\n",
       "         0.69641775,  0.79752219],\n",
       "       ..., \n",
       "       [ 0.00841192,  0.01366395,  0.53732932, ...,  0.08155674,\n",
       "         0.07537536,  0.07692103],\n",
       "       [ 0.90377617,  0.96592015,  0.98436731, ...,  0.98901641,\n",
       "         0.98044145,  0.9684335 ],\n",
       "       [ 0.0747021 ,  0.01449165,  0.20927182, ...,  0.16606021,\n",
       "         0.27188161,  0.05889074]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MNIST_MTL.predicted_vals_logreg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MNIST_MTL.train_model(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score : 0.980420 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.98041999999999996"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MNIST_MTL.accuracy_log_reg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.47362512  0.18747789 -0.09561399 ...,  0.17751911 -0.53015506\n",
      "   0.50892061]\n",
      " [ 0.48472929 -0.62637842  0.5954116  ...,  0.12606943 -0.66368026\n",
      "  -0.7585848 ]\n",
      " [-0.04911496  0.44561294  0.64935881 ..., -0.1788629   0.33259752\n",
      "  -0.02955511]\n",
      " ..., \n",
      " [-0.20487256  0.59768224  0.59859228 ...,  0.15364726  0.26784071\n",
      "  -0.72111851]\n",
      " [-0.31096086  0.05403042 -0.45201683 ...,  0.30278146 -0.65051121\n",
      "   0.03166183]\n",
      " [ 0.3239423  -0.13641159 -0.44111899 ...,  0.0477186  -0.58310646\n",
      "  -0.49803132]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  7.11062133e-01,   4.57554549e-01,   9.75120664e-02,\n",
       "         -5.07937050e+00,  -3.83276868e+00,   5.47499716e-01,\n",
       "          7.71603918e+00,   1.36168015e+00,   3.17900872e+00,\n",
       "         -2.18454540e-01,  -2.86413026e+00,  -4.37900066e+00,\n",
       "         -2.17216992e+00,  -6.29720163e+00,   3.04203176e+00,\n",
       "         -5.22348732e-02,   1.34919095e+00,   4.03648329e+00,\n",
       "         -4.14651203e+00,  -5.77749729e+00,  -2.90662193e+00,\n",
       "         -3.27267551e+00,  -4.66104698e+00,   5.65531969e+00,\n",
       "          4.85670775e-01],\n",
       "       [ -9.64691222e-01,  -6.14411163e+00,  -7.89063311e+00,\n",
       "          2.64467096e+00,   1.46627915e+00,  -3.22474170e+00,\n",
       "         -1.01905584e+00,  -1.88596475e+00,   7.01221895e+00,\n",
       "          1.92705405e+00,   2.55174327e+00,   1.04782128e+00,\n",
       "         -5.82779360e+00,   3.49170709e+00,   6.75916958e+00,\n",
       "          2.16688132e+00,   5.75238085e+00,  -3.99549007e+00,\n",
       "          1.14223826e+00,  -3.51164603e+00,   1.34314454e+00,\n",
       "          3.65567946e+00,   1.13587379e-01,  -5.55841112e+00,\n",
       "         -5.92364883e+00],\n",
       "       [ -6.39417708e-01,   3.38985538e+00,  -3.20516133e+00,\n",
       "         -5.39822042e-01,  -5.74882793e+00,  -5.57149768e-01,\n",
       "          4.90440190e-01,  -2.76023102e+00,  -4.99793005e+00,\n",
       "         -6.13943529e+00,  -4.86437082e+00,   1.80150628e+00,\n",
       "         -2.43367410e+00,   5.27764797e+00,  -6.62898493e+00,\n",
       "          4.37618375e-01,   4.27750015e+00,  -2.12696409e+00,\n",
       "          4.19394159e+00,   5.73637605e-01,   1.46028674e+00,\n",
       "         -1.85208154e+00,   3.50097370e+00,   6.81654167e+00,\n",
       "          3.72835803e+00],\n",
       "       [  5.72197735e-01,   1.68034172e+00,  -3.00833821e+00,\n",
       "         -4.48841381e+00,   5.16429281e+00,  -4.16888475e+00,\n",
       "         -6.96294880e+00,  -1.28992057e+00,  -2.63191819e-01,\n",
       "         -1.80943739e+00,  -6.06960821e+00,  -6.07639885e+00,\n",
       "         -1.68026042e+00,  -2.49091673e+00,   2.72927237e+00,\n",
       "          4.20622349e+00,  -6.85564899e+00,   8.40938282e+00,\n",
       "          3.71062899e+00,   4.54962540e+00,  -1.98130476e+00,\n",
       "          4.28268671e+00,  -3.92813444e+00,  -4.68170261e+00,\n",
       "         -3.60260940e+00],\n",
       "       [  2.54607844e+00,  -7.96052980e+00,  -2.66434860e+00,\n",
       "         -2.93493319e+00,  -2.69420886e+00,   2.50106549e+00,\n",
       "          3.34071350e+00,  -2.57470822e+00,   4.58119583e+00,\n",
       "         -6.90563297e+00,   3.39330125e+00,   2.23719907e+00,\n",
       "          3.48375678e+00,  -5.02125692e+00,  -8.19848251e+00,\n",
       "         -1.71341038e+00,  -5.05596447e+00,   6.00544357e+00,\n",
       "         -6.56114340e-01,  -1.66288626e+00,   6.16928673e+00,\n",
       "         -2.33877707e+00,   3.89905548e+00,  -5.27366161e+00,\n",
       "          4.28496420e-01],\n",
       "       [ -3.05176616e+00,  -1.78837430e+00,   7.71145201e+00,\n",
       "          4.71982098e+00,  -3.77251506e+00,  -1.15936108e+01,\n",
       "         -1.03705215e+01,   6.77015543e+00,   1.57322168e-01,\n",
       "         -8.24020922e-01,   1.67905545e+00,  -1.78405321e+00,\n",
       "         -7.02612519e-01,   1.29097593e+00,   4.61267138e+00,\n",
       "          7.27420330e+00,  -6.49334812e+00,  -9.20294094e+00,\n",
       "          4.45572805e+00,   6.66842163e-01,   5.05022955e+00,\n",
       "         -4.36325932e+00,  -5.60956860e+00,  -2.40490198e+00,\n",
       "          4.14503574e+00],\n",
       "       [  3.16660190e+00,  -4.45554256e+00,  -8.53040874e-01,\n",
       "          1.87503129e-01,   3.07649398e+00,  -4.22100449e+00,\n",
       "         -3.50551677e+00,   1.83885932e+00,   2.24337983e+00,\n",
       "         -4.28148890e+00,  -4.76952076e+00,   2.70211458e+00,\n",
       "          3.59806252e+00,  -7.04305601e+00,   3.61042929e+00,\n",
       "         -5.86637259e+00,   4.11456347e+00,  -3.98823214e+00,\n",
       "         -4.80216026e+00,   4.52647972e+00,  -7.22660494e+00,\n",
       "          1.45237148e-01,  -3.31796020e-01,   6.53981590e+00,\n",
       "         -1.41842246e+00],\n",
       "       [ -1.80336964e+00,   8.29802036e-01,   3.64742970e+00,\n",
       "         -2.13532329e+00,   2.97970319e+00,  -2.54826999e+00,\n",
       "          5.18451631e-01,   7.25896454e+00,  -3.89744210e+00,\n",
       "         -3.08217072e+00,   7.56499863e+00,   4.09100199e+00,\n",
       "         -7.79509687e+00,  -3.42566800e+00,   1.08090663e+00,\n",
       "         -2.89872932e+00,  -2.74361014e+00,  -1.76804709e+00,\n",
       "          6.18264246e+00,  -5.52989483e+00,  -2.50305200e+00,\n",
       "         -5.23402739e+00,   6.55207300e+00,  -5.23101330e+00,\n",
       "         -6.57023430e+00],\n",
       "       [  3.09581041e+00,  -2.72198647e-01,   1.52220082e+00,\n",
       "          6.30821896e+00,  -3.80636024e+00,   2.36185217e+00,\n",
       "         -1.18582726e+00,  -5.26250982e+00,  -6.28981304e+00,\n",
       "          3.22874022e+00,  -6.88107872e+00,   2.49213648e+00,\n",
       "          4.94375658e+00,  -1.33158898e+00,  -9.53457475e-01,\n",
       "         -9.96722794e+00,  -7.79621029e+00,   2.17832088e+00,\n",
       "         -4.02353048e+00,  -2.39235783e+00,   2.79603124e+00,\n",
       "         -3.93508315e+00,  -4.85469151e+00,   4.19522619e+00,\n",
       "         -4.63762474e+00],\n",
       "       [ -3.33755684e+00,   4.57075739e+00,  -4.37777138e+00,\n",
       "          2.42956066e+00,  -3.74254751e+00,  -8.17862332e-01,\n",
       "          2.52893835e-01,  -5.16166925e+00,  -4.43093204e+00,\n",
       "          8.01136875e+00,  -5.95063388e-01,  -8.98904037e+00,\n",
       "          1.42401373e+00,  -7.24769258e+00,  -1.48296952e+00,\n",
       "         -8.67474616e-01,  -2.32061291e+00,  -2.56787968e+00,\n",
       "         -1.69821453e+00,  -6.43771887e+00,  -5.80188227e+00,\n",
       "          4.79170799e+00,  -7.73105025e-01,  -6.07473543e-04,\n",
       "          6.16166925e+00]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print( MNIST_MTL.Thetas[0].Theta.get_value() )\n",
    "MNIST_MTL.Thetas[1].Theta.get_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  4.52048823e-07,   1.00000000e+00,   7.51884666e-10, ...,\n",
       "          6.04108479e-08,   1.88120055e-06,   1.62847478e-08],\n",
       "       [  5.50135458e-11,   3.89633271e-07,   3.38999451e-09, ...,\n",
       "          7.60669491e-06,   4.72258321e-09,   7.85911197e-06],\n",
       "       [  2.77830568e-05,   2.95011669e-05,   3.45770331e-06, ...,\n",
       "          8.52322955e-06,   7.60071725e-02,   1.38454227e-04],\n",
       "       ..., \n",
       "       [  1.52943358e-05,   1.54980810e-08,   9.39907186e-05, ...,\n",
       "          7.08678338e-10,   7.70168582e-11,   4.95301133e-09],\n",
       "       [  9.09049849e-11,   7.11831039e-13,   5.01017041e-07, ...,\n",
       "          9.96697187e-01,   1.42343296e-02,   9.99997377e-01],\n",
       "       [  1.09123675e-05,   1.50772337e-06,   9.65651736e-08, ...,\n",
       "          1.19623294e-07,   9.40610245e-02,   1.57795876e-06]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MNIST_MTL.predicted_vals_logreg()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the mode; cf. [Getting Started, DeepLearning 0.1 documentation, Loading and Saving Models](http://deeplearning.net/tutorial/gettingstarted.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file = open('./saved_models/MNIST_MTL_log_reg','wb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for Thet in MNIST_MTL.Thetas:\n",
    "    cPickle.dump( Thet.Theta.get_value(borrow=True), save_file,-1) # the -1 is for HIGHEST priority\n",
    "    cPickle.dump( Thet.b.get_value(borrow=True), save_file,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_MTL.Thetas[0].al.set_value( valid_set[0].T.astype(theano.config.floatX) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 10000)\n"
     ]
    }
   ],
   "source": [
    "K=10\n",
    "m = len(valid_set[1])\n",
    "y_valid_prob = [np.zeros(K) for row in valid_set[1]]  # list of 5000 numpy arrays of size dims. (10,)\n",
    "for i in range( m):\n",
    "        y_valid_prob[i][ valid_set[1][i]] = 1\n",
    "y_valid_prob = np.array(y_valid_prob).T.astype(theano.config.floatX)  # size dims. (K,m)\n",
    "print( y_valid_prob.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MNIST_MTL.y = y_valid_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "dimension mismatch in args to gemm (25,784)x(784,10000)->(25,50000)\nApply node that caused the error: GpuGemm{inplace}(GpuReshape{2}.0, TensorConstant{1.0}, Theta1, al, TensorConstant{1.0})\nToposort index: 14\nInputs types: [CudaNdarrayType(float32, matrix), TensorType(float32, scalar), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), TensorType(float32, scalar)]\nInputs shapes: [(25, 50000), (), (25, 784), (784, 10000), ()]\nInputs strides: [(50000, 1), (), (784, 1), (10000, 1), ()]\nInputs values: ['not shown', array(1.0, dtype=float32), 'not shown', 'not shown', array(1.0, dtype=float32)]\nOutputs clients: [[GpuElemwise{ScalarSigmoid}[(0, 0)](GpuGemm{inplace}.0)]]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-ec623bb772a5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mMNIST_MTL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredicted_vals_logreg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/topolo/PropD/MLgrabbag/ML/NN.py\u001b[0m in \u001b[0;36mpredicted_vals_logreg\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    311\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mpredicted_vals_logreg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m                 \u001b[0mpredict_vals_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredicted_logreg\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mThetas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malp1\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 313\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mpredict_vals_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# do the actual prediction on actual values, with the inputted X and trained Thetas,b's\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    314\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/topolo/Public/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    869\u001b[0m                     \u001b[0mnode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m                     \u001b[0mthunk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mthunk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 871\u001b[1;33m                     storage_map=getattr(self.fn, 'storage_map', None))\n\u001b[0m\u001b[0;32m    872\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    873\u001b[0m                 \u001b[1;31m# old-style linkers raise their own exceptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/topolo/Public/anaconda2/lib/python2.7/site-packages/theano/gof/link.pyc\u001b[0m in \u001b[0;36mraise_with_op\u001b[1;34m(node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[0;32m    312\u001b[0m         \u001b[1;31m# extra long error message in that case.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m     \u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/topolo/Public/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: dimension mismatch in args to gemm (25,784)x(784,10000)->(25,50000)\nApply node that caused the error: GpuGemm{inplace}(GpuReshape{2}.0, TensorConstant{1.0}, Theta1, al, TensorConstant{1.0})\nToposort index: 14\nInputs types: [CudaNdarrayType(float32, matrix), TensorType(float32, scalar), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), TensorType(float32, scalar)]\nInputs shapes: [(25, 50000), (), (25, 784), (784, 10000), ()]\nInputs strides: [(50000, 1), (), (784, 1), (10000, 1), ()]\nInputs values: ['not shown', array(1.0, dtype=float32), 'not shown', 'not shown', array(1.0, dtype=float32)]\nOutputs clients: [[GpuElemwise{ScalarSigmoid}[(0, 0)](GpuGemm{inplace}.0)]]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node."
     ]
    }
   ],
   "source": [
    "MNIST_MTL.predicted_vals_logreg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "dimension mismatch in args to gemm (25,784)x(784,10000)->(25,50000)\nApply node that caused the error: GpuGemm{inplace}(GpuReshape{2}.0, TensorConstant{1.0}, Theta1, al, TensorConstant{1.0})\nToposort index: 7\nInputs types: [CudaNdarrayType(float32, matrix), TensorType(float32, scalar), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), TensorType(float32, scalar)]\nInputs shapes: [(25, 50000), (), (25, 784), (784, 10000), ()]\nInputs strides: [(50000, 1), (), (784, 1), (10000, 1), ()]\nInputs values: ['not shown', array(1.0, dtype=float32), 'not shown', 'not shown', array(1.0, dtype=float32)]\nOutputs clients: [[GpuElemwise{ScalarSigmoid}[(0, 0)](GpuGemm{inplace}.0)]]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-10646c6daf13>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMNIST_MTL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mThetas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malp1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/topolo/Public/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    869\u001b[0m                     \u001b[0mnode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m                     \u001b[0mthunk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mthunk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 871\u001b[1;33m                     storage_map=getattr(self.fn, 'storage_map', None))\n\u001b[0m\u001b[0;32m    872\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    873\u001b[0m                 \u001b[1;31m# old-style linkers raise their own exceptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/topolo/Public/anaconda2/lib/python2.7/site-packages/theano/gof/link.pyc\u001b[0m in \u001b[0;36mraise_with_op\u001b[1;34m(node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[0;32m    312\u001b[0m         \u001b[1;31m# extra long error message in that case.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m     \u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/topolo/Public/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: dimension mismatch in args to gemm (25,784)x(784,10000)->(25,50000)\nApply node that caused the error: GpuGemm{inplace}(GpuReshape{2}.0, TensorConstant{1.0}, Theta1, al, TensorConstant{1.0})\nToposort index: 7\nInputs types: [CudaNdarrayType(float32, matrix), TensorType(float32, scalar), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), TensorType(float32, scalar)]\nInputs shapes: [(25, 50000), (), (25, 784), (784, 10000), ()]\nInputs strides: [(50000, 1), (), (784, 1), (10000, 1), ()]\nInputs values: ['not shown', array(1.0, dtype=float32), 'not shown', 'not shown', array(1.0, dtype=float32)]\nOutputs clients: [[GpuElemwise{ScalarSigmoid}[(0, 0)](GpuGemm{inplace}.0)]]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node."
     ]
    }
   ],
   "source": [
    "theano.function([], MNIST_MTL.Thetas[0].alp1)()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "Layer1 = MNIST_MTL.Thetas[0]\n",
    "Layer2 = MNIST_MTL.Thetas[1]\n",
    "m = valid_set[0].shape[0]\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 10000)\n"
     ]
    }
   ],
   "source": [
    "a2 = T.nnet.sigmoid( T.dot( Layer1.Theta, Layer1.al) + T.tile( Layer1.b, (1,m)) )\n",
    "a3 = T.nnet.sigmoid( T.dot( Layer2.Theta, a2) + T.tile( Layer2.b, (1,m)) )\n",
    "valid_pred = theano.function([], a3)()\n",
    "print( valid_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>1.000000e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.992079e-02</td>\n",
       "      <td>1.074899e-01</td>\n",
       "      <td>9.912494e-02</td>\n",
       "      <td>1.052671e-01</td>\n",
       "      <td>9.976897e-02</td>\n",
       "      <td>9.037534e-02</td>\n",
       "      <td>9.769981e-02</td>\n",
       "      <td>1.085759e-01</td>\n",
       "      <td>1.005443e-01</td>\n",
       "      <td>9.500753e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.961449e-01</td>\n",
       "      <td>3.058113e-01</td>\n",
       "      <td>2.902825e-01</td>\n",
       "      <td>2.958724e-01</td>\n",
       "      <td>2.931867e-01</td>\n",
       "      <td>2.795904e-01</td>\n",
       "      <td>2.927824e-01</td>\n",
       "      <td>3.047731e-01</td>\n",
       "      <td>2.924316e-01</td>\n",
       "      <td>2.828876e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9.005615e-17</td>\n",
       "      <td>1.986378e-17</td>\n",
       "      <td>2.439026e-13</td>\n",
       "      <td>6.265842e-16</td>\n",
       "      <td>1.214437e-18</td>\n",
       "      <td>6.500246e-18</td>\n",
       "      <td>9.674661e-19</td>\n",
       "      <td>1.735837e-17</td>\n",
       "      <td>3.318569e-18</td>\n",
       "      <td>6.359484e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.320481e-09</td>\n",
       "      <td>1.788181e-09</td>\n",
       "      <td>4.365240e-07</td>\n",
       "      <td>1.482097e-07</td>\n",
       "      <td>1.504599e-09</td>\n",
       "      <td>4.772580e-09</td>\n",
       "      <td>1.436151e-10</td>\n",
       "      <td>3.032865e-09</td>\n",
       "      <td>3.319625e-08</td>\n",
       "      <td>1.242549e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.058250e-08</td>\n",
       "      <td>1.760941e-07</td>\n",
       "      <td>1.530497e-05</td>\n",
       "      <td>8.275158e-06</td>\n",
       "      <td>3.291525e-07</td>\n",
       "      <td>4.075375e-07</td>\n",
       "      <td>2.823017e-08</td>\n",
       "      <td>4.088125e-07</td>\n",
       "      <td>3.484185e-06</td>\n",
       "      <td>1.585515e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.096723e-05</td>\n",
       "      <td>3.165664e-05</td>\n",
       "      <td>5.320824e-04</td>\n",
       "      <td>4.356618e-04</td>\n",
       "      <td>3.269091e-05</td>\n",
       "      <td>3.865018e-05</td>\n",
       "      <td>6.124497e-06</td>\n",
       "      <td>8.373335e-05</td>\n",
       "      <td>2.405906e-04</td>\n",
       "      <td>2.055749e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.999994e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0             1             2             3             4  \\\n",
       "count  1.000000e+04  1.000000e+04  1.000000e+04  1.000000e+04  1.000000e+04   \n",
       "mean   9.992079e-02  1.074899e-01  9.912494e-02  1.052671e-01  9.976897e-02   \n",
       "std    2.961449e-01  3.058113e-01  2.902825e-01  2.958724e-01  2.931867e-01   \n",
       "min    9.005615e-17  1.986378e-17  2.439026e-13  6.265842e-16  1.214437e-18   \n",
       "25%    1.320481e-09  1.788181e-09  4.365240e-07  1.482097e-07  1.504599e-09   \n",
       "50%    9.058250e-08  1.760941e-07  1.530497e-05  8.275158e-06  3.291525e-07   \n",
       "75%    1.096723e-05  3.165664e-05  5.320824e-04  4.356618e-04  3.269091e-05   \n",
       "max    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "\n",
       "                  5             6             7             8             9  \n",
       "count  1.000000e+04  1.000000e+04  1.000000e+04  1.000000e+04  1.000000e+04  \n",
       "mean   9.037534e-02  9.769981e-02  1.085759e-01  1.005443e-01  9.500753e-02  \n",
       "std    2.795904e-01  2.927824e-01  3.047731e-01  2.924316e-01  2.828876e-01  \n",
       "min    6.500246e-18  9.674661e-19  1.735837e-17  3.318569e-18  6.359484e-18  \n",
       "25%    4.772580e-09  1.436151e-10  3.032865e-09  3.319625e-08  1.242549e-08  \n",
       "50%    4.075375e-07  2.823017e-08  4.088125e-07  3.484185e-06  1.585515e-06  \n",
       "75%    3.865018e-05  6.124497e-06  8.373335e-05  2.405906e-04  2.055749e-04  \n",
       "max    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  9.999994e-01  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame( valid_pred.T).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95340000000000003"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean( np.vstack( np.argmax( valid_pred,axis=0)) == np.vstack( valid_set[1] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_in = T.matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TensorVariable' object has no attribute 'set_value'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-922d1dc9b484>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_in\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_value\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mvalid_set\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloatX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'TensorVariable' object has no attribute 'set_value'"
     ]
    }
   ],
   "source": [
    "X_in.set_value( valid_set[0].T.astype(theano.config.floatX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2_giv = T.nnet.sigmoid( T.dot( Layer1.Theta, X_in) + T.tile(Layer1.b, (1,m)))\n",
    "a3_giv = T.nnet.sigmoid( T.dot( Layer2.Theta, a2_giv) + T.tile( Layer2.b, (1,m)) )\n",
    "valid_pred_givens = theano.function([], outputs=a3_giv, givens={ X_in: valid_set[0].T.astype(theano.config.floatX)} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 10000)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>1.000000e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.992079e-02</td>\n",
       "      <td>1.074899e-01</td>\n",
       "      <td>9.912494e-02</td>\n",
       "      <td>1.052671e-01</td>\n",
       "      <td>9.976897e-02</td>\n",
       "      <td>9.037534e-02</td>\n",
       "      <td>9.769981e-02</td>\n",
       "      <td>1.085759e-01</td>\n",
       "      <td>1.005443e-01</td>\n",
       "      <td>9.500753e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.961449e-01</td>\n",
       "      <td>3.058113e-01</td>\n",
       "      <td>2.902825e-01</td>\n",
       "      <td>2.958724e-01</td>\n",
       "      <td>2.931867e-01</td>\n",
       "      <td>2.795904e-01</td>\n",
       "      <td>2.927824e-01</td>\n",
       "      <td>3.047731e-01</td>\n",
       "      <td>2.924316e-01</td>\n",
       "      <td>2.828876e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9.005615e-17</td>\n",
       "      <td>1.986378e-17</td>\n",
       "      <td>2.439026e-13</td>\n",
       "      <td>6.265842e-16</td>\n",
       "      <td>1.214437e-18</td>\n",
       "      <td>6.500246e-18</td>\n",
       "      <td>9.674661e-19</td>\n",
       "      <td>1.735837e-17</td>\n",
       "      <td>3.318569e-18</td>\n",
       "      <td>6.359484e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.320481e-09</td>\n",
       "      <td>1.788181e-09</td>\n",
       "      <td>4.365240e-07</td>\n",
       "      <td>1.482097e-07</td>\n",
       "      <td>1.504599e-09</td>\n",
       "      <td>4.772580e-09</td>\n",
       "      <td>1.436151e-10</td>\n",
       "      <td>3.032865e-09</td>\n",
       "      <td>3.319625e-08</td>\n",
       "      <td>1.242549e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.058250e-08</td>\n",
       "      <td>1.760941e-07</td>\n",
       "      <td>1.530497e-05</td>\n",
       "      <td>8.275158e-06</td>\n",
       "      <td>3.291525e-07</td>\n",
       "      <td>4.075375e-07</td>\n",
       "      <td>2.823017e-08</td>\n",
       "      <td>4.088125e-07</td>\n",
       "      <td>3.484185e-06</td>\n",
       "      <td>1.585515e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.096723e-05</td>\n",
       "      <td>3.165664e-05</td>\n",
       "      <td>5.320824e-04</td>\n",
       "      <td>4.356618e-04</td>\n",
       "      <td>3.269091e-05</td>\n",
       "      <td>3.865018e-05</td>\n",
       "      <td>6.124497e-06</td>\n",
       "      <td>8.373335e-05</td>\n",
       "      <td>2.405906e-04</td>\n",
       "      <td>2.055749e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.999994e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0             1             2             3             4  \\\n",
       "count  1.000000e+04  1.000000e+04  1.000000e+04  1.000000e+04  1.000000e+04   \n",
       "mean   9.992079e-02  1.074899e-01  9.912494e-02  1.052671e-01  9.976897e-02   \n",
       "std    2.961449e-01  3.058113e-01  2.902825e-01  2.958724e-01  2.931867e-01   \n",
       "min    9.005615e-17  1.986378e-17  2.439026e-13  6.265842e-16  1.214437e-18   \n",
       "25%    1.320481e-09  1.788181e-09  4.365240e-07  1.482097e-07  1.504599e-09   \n",
       "50%    9.058250e-08  1.760941e-07  1.530497e-05  8.275158e-06  3.291525e-07   \n",
       "75%    1.096723e-05  3.165664e-05  5.320824e-04  4.356618e-04  3.269091e-05   \n",
       "max    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "\n",
       "                  5             6             7             8             9  \n",
       "count  1.000000e+04  1.000000e+04  1.000000e+04  1.000000e+04  1.000000e+04  \n",
       "mean   9.037534e-02  9.769981e-02  1.085759e-01  1.005443e-01  9.500753e-02  \n",
       "std    2.795904e-01  2.927824e-01  3.047731e-01  2.924316e-01  2.828876e-01  \n",
       "min    6.500246e-18  9.674661e-19  1.735837e-17  3.318569e-18  6.359484e-18  \n",
       "25%    4.772580e-09  1.436151e-10  3.032865e-09  3.319625e-08  1.242549e-08  \n",
       "50%    4.075375e-07  2.823017e-08  4.088125e-07  3.484185e-06  1.585515e-06  \n",
       "75%    3.865018e-05  6.124497e-06  8.373335e-05  2.405906e-04  2.055749e-04  \n",
       "max    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  9.999994e-01  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print( valid_pred_givens().shape )\n",
    "pd.DataFrame( valid_pred_givens().T).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95340000000000003"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean( np.vstack( np.argmax( valid_pred_givens(),axis=0)) == np.vstack( valid_set[1] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_pred_givens = theano.function([], outputs=a3_giv, givens={ X_in: test_set[0].T.astype(theano.config.floatX)} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94979999999999998"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean( np.vstack( np.argmax( test_pred_givens(),axis=0)) == np.vstack( test_set[1] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(1,3-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "cf. [Glass Classification](https://www.kaggle.com/uciml/glass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gls_data = pd.read_csv( \"./kaggle/glass.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RI</th>\n",
       "      <th>Na</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Al</th>\n",
       "      <th>Si</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Ba</th>\n",
       "      <th>Fe</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.518365</td>\n",
       "      <td>13.407850</td>\n",
       "      <td>2.684533</td>\n",
       "      <td>1.444907</td>\n",
       "      <td>72.650935</td>\n",
       "      <td>0.497056</td>\n",
       "      <td>8.956963</td>\n",
       "      <td>0.175047</td>\n",
       "      <td>0.057009</td>\n",
       "      <td>2.780374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.003037</td>\n",
       "      <td>0.816604</td>\n",
       "      <td>1.442408</td>\n",
       "      <td>0.499270</td>\n",
       "      <td>0.774546</td>\n",
       "      <td>0.652192</td>\n",
       "      <td>1.423153</td>\n",
       "      <td>0.497219</td>\n",
       "      <td>0.097439</td>\n",
       "      <td>2.103739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.511150</td>\n",
       "      <td>10.730000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>69.810000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.430000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.516523</td>\n",
       "      <td>12.907500</td>\n",
       "      <td>2.115000</td>\n",
       "      <td>1.190000</td>\n",
       "      <td>72.280000</td>\n",
       "      <td>0.122500</td>\n",
       "      <td>8.240000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.517680</td>\n",
       "      <td>13.300000</td>\n",
       "      <td>3.480000</td>\n",
       "      <td>1.360000</td>\n",
       "      <td>72.790000</td>\n",
       "      <td>0.555000</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.519157</td>\n",
       "      <td>13.825000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>1.630000</td>\n",
       "      <td>73.087500</td>\n",
       "      <td>0.610000</td>\n",
       "      <td>9.172500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.533930</td>\n",
       "      <td>17.380000</td>\n",
       "      <td>4.490000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>75.410000</td>\n",
       "      <td>6.210000</td>\n",
       "      <td>16.190000</td>\n",
       "      <td>3.150000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               RI          Na          Mg          Al          Si           K  \\\n",
       "count  214.000000  214.000000  214.000000  214.000000  214.000000  214.000000   \n",
       "mean     1.518365   13.407850    2.684533    1.444907   72.650935    0.497056   \n",
       "std      0.003037    0.816604    1.442408    0.499270    0.774546    0.652192   \n",
       "min      1.511150   10.730000    0.000000    0.290000   69.810000    0.000000   \n",
       "25%      1.516523   12.907500    2.115000    1.190000   72.280000    0.122500   \n",
       "50%      1.517680   13.300000    3.480000    1.360000   72.790000    0.555000   \n",
       "75%      1.519157   13.825000    3.600000    1.630000   73.087500    0.610000   \n",
       "max      1.533930   17.380000    4.490000    3.500000   75.410000    6.210000   \n",
       "\n",
       "               Ca          Ba          Fe        Type  \n",
       "count  214.000000  214.000000  214.000000  214.000000  \n",
       "mean     8.956963    0.175047    0.057009    2.780374  \n",
       "std      1.423153    0.497219    0.097439    2.103739  \n",
       "min      5.430000    0.000000    0.000000    1.000000  \n",
       "25%      8.240000    0.000000    0.000000    1.000000  \n",
       "50%      8.600000    0.000000    0.000000    2.000000  \n",
       "75%      9.172500    0.000000    0.100000    3.000000  \n",
       "max     16.190000    3.150000    0.510000    7.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gls_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(214, 10)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gls_data.get_values().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(214, 9)\n",
      "(214,)\n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      "(200, 9)\n",
      "(200,)\n"
     ]
    }
   ],
   "source": [
    "X_gls = gls_data.get_values()[:,:-1]\n",
    "print(X_gls.shape)\n",
    "y_gls = gls_data.get_values()[:,-1]\n",
    "print(y_gls.shape)\n",
    "print( y_gls[:10])\n",
    "X_gls_train = gls_data.get_values()[:-14,:-1]\n",
    "print(X_gls_train.shape)\n",
    "y_gls_train = gls_data.get_values()[:-14,-1]\n",
    "print(y_gls_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 200)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/topolo/Public/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:5: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "K=7\n",
    "m = len(y_gls_train)\n",
    "y_gls_train_prob = [np.zeros(K) for row in y_gls_train]  # list of 5000 numpy arrays of size dims. (10,)\n",
    "for i in range( m):\n",
    "        y_gls_train_prob[i][ y_gls_train[i]-1] = 1\n",
    "y_gls_train_prob = np.array(y_gls_train_prob).T.astype(theano.config.floatX)  # size dims. (K,m)\n",
    "print( y_gls_train_prob.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "gls_MLP = MLP( 3, [9,8,7],200, X_gls_train.T, y_gls_train_prob, T.nnet.sigmoid, 0.01,0.05,0.0001 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score : 0.045000 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.044999999999999998"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gls_MLP.accuracy_log_reg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gls_MLP.train_model(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score : 0.380000 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.38"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gls_MLP.accuracy_log_reg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.34978667,  0.34978667,  0.34978667, ...,  0.34978667,\n",
       "         0.34978667,  0.34978667],\n",
       "       [ 0.3797904 ,  0.3797904 ,  0.3797904 , ...,  0.3797904 ,\n",
       "         0.3797904 ,  0.3797904 ],\n",
       "       [ 0.08406211,  0.08406211,  0.08406211, ...,  0.08406211,\n",
       "         0.08406211,  0.08406211],\n",
       "       ..., \n",
       "       [ 0.06395678,  0.06395678,  0.06395678, ...,  0.06395678,\n",
       "         0.06395678,  0.06395678],\n",
       "       [ 0.04376425,  0.04376425,  0.04376425, ...,  0.04376425,\n",
       "         0.04376425,  0.04376425],\n",
       "       [ 0.07399232,  0.07399232,  0.07399232, ...,  0.07399232,\n",
       "         0.07399232,  0.07399232]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gls_MLP.predicted_vals_logreg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score : 0.380000 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.38"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gls_MLP.train_model(10000)\n",
    "gls_MLP.accuracy_log_reg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14, 9)\n",
      "(14,)\n"
     ]
    }
   ],
   "source": [
    "X_gls_test = gls_data.get_values()[-14:,:-1]\n",
    "print( X_gls_test.shape )\n",
    "y_gls_test = gls_data.get_values()[-14:,-1]\n",
    "print( y_gls_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "gls_predict_on_test = gls_MLP.predict_on( 14, X_gls_test.T )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean( np.vstack( np.argmax( gls_predict_on_test(), axis=0) ) == (y_gls_test-1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_gls_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vstack( np.argmax( gls_predict_on_test(), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_sym = T.matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(1234)\n",
    "Thetab1 = Layer( rng, 1, 4,3,2, al = X_sym, activation=T.nnet.sigmoid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Thetab1.alp1\n",
    "Thetab1.Theta.get_value().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Thetab2 = Layer( rng, 2, 3,2,2, al=Thetab1.alp1, activation=T.nnet.sigmoid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Thetab2.al = Thetab1.alp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Subtensor{int64}.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sym.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reshape{2}.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.tile( Thetab1.b, (1, X_sym.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test12comp = theano.function( [], outputs=Thetab2.alp1, givens={ X_sym : X42test} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X42test = np.array([1,2,3,4,5,6,7,8]).reshape((4,2)).astype(theano.config.floatX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.91000074,  0.91101253],\n",
       "       [ 0.02431746,  0.02417665]], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test12comp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X43test = np.array(range(1,13)).reshape((4,3)).astype(theano.config.floatX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.,   2.,   3.],\n",
       "       [  4.,   5.,   6.],\n",
       "       [  7.,   8.,   9.],\n",
       "       [ 10.,  11.,  12.]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X43test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test43comp = theano.function( [], outputs=Thetab2.alp1, givens={ X_sym : X43test} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "dimension mismatch in args to gemm (3,4)x(4,3)->(3,2)\nApply node that caused the error: GpuGemm{inplace}(GpuReshape{2}.0, TensorConstant{1.0}, Theta1, <CudaNdarrayType(float32, matrix)>, TensorConstant{1.0})\nToposort index: 14\nInputs types: [CudaNdarrayType(float32, matrix), TensorType(float32, scalar), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), TensorType(float32, scalar)]\nInputs shapes: [(3, 2), (), (3, 4), (4, 3), ()]\nInputs strides: [(2, 1), (), (4, 1), (3, 1), ()]\nInputs values: ['not shown', array(1.0, dtype=float32), 'not shown', 'not shown', array(1.0, dtype=float32)]\nOutputs clients: [[GpuElemwise{ScalarSigmoid}[(0, 0)](GpuGemm{inplace}.0)]]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-4a3d91ae9a55>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest43comp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/topolo/Public/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    869\u001b[0m                     \u001b[0mnode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m                     \u001b[0mthunk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mthunk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 871\u001b[1;33m                     storage_map=getattr(self.fn, 'storage_map', None))\n\u001b[0m\u001b[0;32m    872\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    873\u001b[0m                 \u001b[1;31m# old-style linkers raise their own exceptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/topolo/Public/anaconda2/lib/python2.7/site-packages/theano/gof/link.pyc\u001b[0m in \u001b[0;36mraise_with_op\u001b[1;34m(node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[0;32m    312\u001b[0m         \u001b[1;31m# extra long error message in that case.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m     \u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/topolo/Public/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: dimension mismatch in args to gemm (3,4)x(4,3)->(3,2)\nApply node that caused the error: GpuGemm{inplace}(GpuReshape{2}.0, TensorConstant{1.0}, Theta1, <CudaNdarrayType(float32, matrix)>, TensorConstant{1.0})\nToposort index: 14\nInputs types: [CudaNdarrayType(float32, matrix), TensorType(float32, scalar), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), TensorType(float32, scalar)]\nInputs shapes: [(3, 2), (), (3, 4), (4, 3), ()]\nInputs strides: [(2, 1), (), (4, 1), (3, 1), ()]\nInputs values: ['not shown', array(1.0, dtype=float32), 'not shown', 'not shown', array(1.0, dtype=float32)]\nOutputs clients: [[GpuElemwise{ScalarSigmoid}[(0, 0)](GpuGemm{inplace}.0)]]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node."
     ]
    }
   ],
   "source": [
    "test43comp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'theano.tensor.var.TensorVariable'>\n"
     ]
    }
   ],
   "source": [
    "print( type(Thetab1.al ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lin_zlp1 = T.dot(Thetab1.Theta, Thetab1.al)+T.tile( Thetab1.b, (1,Thetab1.al.shape[1]))\n",
    "a1p1 = Thetab1.g( lin_zlp1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Thetab1.al = X_sym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Thetab2.al = a1p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lin_z2p1 = T.dot(Thetab2.Theta, Thetab2.al)+T.tile( Thetab2.b, (1, Thetab2.al.shape[1]))\n",
    "a2p1 = Thetab2.g( lin_z2p1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_gen_conn = theano.function([], outputs=a2p1, givens={ Thetab1.al : X42test })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.91000074,  0.91101253],\n",
       "       [ 0.02431746,  0.02417665]], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_gen_conn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_gen_conn = theano.function([], outputs=a2p1, givens={ Thetab1.al : X43test })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.91144621,  0.91158789,  0.91166627],\n",
       "       [ 0.02425005,  0.02417867,  0.02417858]], dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_gen_conn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*GPU test*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_gen_conn = theano.function([], outputs=sandbox.cuda.basic_ops.gpu_from_host(a2p1), givens={ Thetab1.al : X42test })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CudaNdarray([[ 0.91000074  0.91101253]\n",
       " [ 0.02431746  0.02417665]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_gen_conn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_gen_conn = theano.function([], outputs=sandbox.cuda.basic_ops.gpu_from_host(a2p1), givens={ Thetab1.al : X43test })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CudaNdarray([[ 0.91144621  0.91158789  0.91166627]\n",
       " [ 0.02425005  0.02417867  0.02417858]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_gen_conn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary for Neural Net with Multiple Layers for logistic regression (but can be extended to linear regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys.path.append( os.getcwd() + '/ML' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from NN import MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and Visualizing Data ... \n",
      "\n",
      "(400, 5000)\n",
      "(10, 5000)\n"
     ]
    }
   ],
   "source": [
    "# Load Training Data\n",
    "print(\"Loading and Visualizing Data ... \\n\")\n",
    "ex4data1 = scipy.io.loadmat('./coursera_Ng/machine-learning-ex4/ex4/ex4data1.mat')\n",
    "\n",
    "# recall that whereas the original labels (in the variable y) were 1, 2, ..., 10, for the purpose of training a \n",
    "# neural network, we need to recode the labels as vectors containing only values 0 or 1\n",
    "K=10\n",
    "m = ex4data1['y'].shape[0]\n",
    "y_prob = [np.zeros(K) for row in ex4data1['y']]  # list of 5000 numpy arrays of size dims. (10,)\n",
    "for i in range( m):\n",
    "        y_prob[i][ ex4data1['y'][i]-1] = 1\n",
    "y_prob = np.array(y_prob).T.astype(theano.config.floatX)  # size dims. (K,m)\n",
    "\n",
    "print(ex4data1['X'].T.shape)\n",
    "print(y_prob.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "digitsMLP = MLP( 3, [400,25,10], ex4data1['X'].T, y_prob, T.nnet.sigmoid, 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "digitsMLP.build_update(ex4data1['X'].T, y_prob, 0.01, 0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01459562,  0.00558456,  0.02797613, ...,  0.0674273 ,\n",
       "         0.04817105,  0.03059   ],\n",
       "       [ 0.99074477,  0.97213686,  0.98990673, ...,  0.94329911,\n",
       "         0.99409556,  0.98447394],\n",
       "       [ 0.02927557,  0.05798027,  0.07752991, ...,  0.36027411,\n",
       "         0.1559844 ,  0.26209033],\n",
       "       ..., \n",
       "       [ 0.00369688,  0.01589782,  0.0115205 , ...,  0.0152018 ,\n",
       "         0.00421828,  0.00280912],\n",
       "       [ 0.78314799,  0.61225456,  0.71571481, ...,  0.80646819,\n",
       "         0.94149739,  0.52025074],\n",
       "       [ 0.96498191,  0.98687011,  0.78228015, ...,  0.95690244,\n",
       "         0.63841748,  0.404479  ]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digitsMLP.predicted_vals_logreg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score : 0.134200 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.13420000000000001"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digitsMLP.accuracy_logreg( ex4data1['X'].T, y_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "digitsMLP.train_model(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score : 0.894600 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.89459999999999995"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digitsMLP.accuracy_logreg( ex4data1['X'].T, y_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "digitsMLP.train_model(50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score : 0.956600 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.95660000000000001"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digitsMLP.accuracy_logreg( ex4data1['X'].T, y_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing on University of Montreal LISA lab MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import six.moves.cPickle as pickle\n",
    "with gzip.open(\"../DeepLearningTutorials/data/mnist.pkl.gz\", 'rb') as f:\n",
    "    try:\n",
    "        train_set, valid_set, test_set = pickle.load(f, encoding='latin1')\n",
    "    except:\n",
    "        train_set, valid_set, test_set = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 50000)\n"
     ]
    }
   ],
   "source": [
    "K=10\n",
    "m = len(train_set[1])\n",
    "y_train_prob = [np.zeros(K) for row in train_set[1]]  # list of 5000 numpy arrays of size dims. (10,)\n",
    "for i in range( m):\n",
    "        y_train_prob[i][ train_set[1][i]] = 1\n",
    "y_train_prob = np.array(y_train_prob).T.astype(theano.config.floatX)  # size dims. (K,m)\n",
    "print( y_train_prob.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MNIST_MLP = MLP( 3,[784,49,10], train_set[0].T, y_train_prob, T.nnet.sigmoid, 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MNIST_MLP.build_update( train_set[0].T, y_train_prob, 0.01, 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score : 0.098660 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.098659999999999998"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MNIST_MLP.accuracy_logreg( train_set[0].T, y_train_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MNIST_MLP.train_model(50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score : 0.862140 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.86214000000000002"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MNIST_MLP.accuracy_logreg( train_set[0].T, y_train_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 38s, sys: 8min 22s, total: 12min\n",
      "Wall time: 12min\n"
     ]
    }
   ],
   "source": [
    "%time MNIST_MLP.train_model(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score : 0.826500 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.82650000000000001"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MNIST_MLP.accuracy_logreg( train_set[0].T,y_train_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 10000)\n"
     ]
    }
   ],
   "source": [
    "m = len(valid_set[1])\n",
    "y_valid_prob = [np.zeros(K) for row in valid_set[1]]  # list of 5000 numpy arrays of size dims. (10,)\n",
    "for i in range( m):\n",
    "        y_valid_prob[i][ valid_set[1][i]] = 1\n",
    "y_valid_prob = np.array(y_valid_prob).T.astype(theano.config.floatX)  # size dims. (K,m)\n",
    "print( y_valid_prob.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 10000)\n"
     ]
    }
   ],
   "source": [
    "m = len(test_set[1])\n",
    "y_test_prob = [np.zeros(K) for row in test_set[1]]  # list of 5000 numpy arrays of size dims. (10,)\n",
    "for i in range( m):\n",
    "        y_test_prob[i][ test_set[1][i]] = 1\n",
    "y_test_prob = np.array(y_test_prob).T.astype(theano.config.floatX)  # size dims. (K,m)\n",
    "print( y_test_prob.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score : 0.814200 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.81420000000000003"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MNIST_MLP.accuracy_logreg( valid_set[0].T,y_valid_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score : 0.805000 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.80500000000000005"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MNIST_MLP.accuracy_logreg( test_set[0].T,y_test_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784\n"
     ]
    }
   ],
   "source": [
    "MNIST_d = train_set[0].T.shape[0]\n",
    "print(MNIST_d)\n",
    "MNIST_MLP = MLP( 3,[MNIST_d,25,10], train_set[0].T, y_train_prob, T.nnet.sigmoid, 1.)\n",
    "MNIST_MLP.build_update( train_set[0].T, y_train_prob, 0.1, 0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score : 0.095720 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.09572"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MNIST_MLP.accuracy_logreg( train_set[0].T, y_train_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MNIST_MLP.train_model(150000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score : 0.986520 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.98651999999999995"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MNIST_MLP.accuracy_logreg( train_set[0].T, y_train_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score : 0.950600 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9506"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MNIST_MLP.accuracy_logreg( valid_set[0].T, y_valid_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score : 0.945200 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.94520000000000004"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MNIST_MLP.accuracy_logreg( test_set[0].T, y_test_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
